{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "In this notebook, a five-fold grouped cross-validation was performed for **Model II** with data from the [German Mouse Clinic](https://www.mouseclinic.de/), where the groups consist of mice.\n",
    "\n",
    "The class score outputs of Model I are used as input for the second model.\n",
    "\n",
    "First, a 4:1 randomly split into training and test mice is done. The training data is then randomly split 4:1 into training and validation mice in each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:02:45.344102Z",
     "start_time": "2021-02-08T17:02:45.063432Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-24T09:14:04.975143Z",
     "start_time": "2021-02-24T09:14:03.391473Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [20, 16]\n",
    "\n",
    "import ABR_ThresholdFinder_NN.data_preparation as dataprep\n",
    "from ABR_ThresholdFinder_NN.models import create_model_1, compile_model_1, create_model_2, compile_model_2\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\"\"\"Define available GPUs\"\"\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "count_gpus = len([int(s) for s in os.environ['CUDA_VISIBLE_DEVICES'].split(',')])\n",
    "print('%d GPUS' % count_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:02:51.103097Z",
     "start_time": "2021-02-08T17:02:51.037370Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Define the batch size\"\"\"\n",
    "batch_size=128\n",
    "\n",
    "\"\"\"Define the cutoff for the hearing threshold\"\"\"\n",
    "threshold_cutoff = 0.5\n",
    "\n",
    "\"\"\"Initialize the sample weight column (for the main label) \"\"\"\n",
    "sample_weight_col = []\n",
    "\n",
    "\"\"\"Define potential sound pressure levels measured in dB\"\"\"\n",
    "sound_levels = [x for x in range(0, 100, 5)] \n",
    "print(*['potential sound pressure levels [dB]: ' + str(x) if x==0 else str(x) for x in sound_levels], sep = \", \") \n",
    "aul_sound_level = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:03:03.580332Z",
     "start_time": "2021-02-08T17:03:03.521310Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Set the path to the data files, for example '../data/GMC'\"\"\"\n",
    "data_dir = ''\n",
    "\"\"\"Set the saving location for the models\"\"\"\n",
    "save_dir = '../models_cross-validation/GMC/cv_network_2/'\n",
    "data_file = '../models_cross-validation/GMC/model_1_predicted_curves.csv'\n",
    "if os.path.exists(data_file):\n",
    "    print('data file: {}'.format(data_file))\n",
    "else: \n",
    "    print('ERROR: data file not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:03:05.815374Z",
     "start_time": "2021-02-08T17:03:05.555968Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Load the output data of the first model\"\"\"\n",
    "data = pd.read_csv(data_file)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:03:11.629097Z",
     "start_time": "2021-02-08T17:03:09.052541Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Prepare the data for the cross validation approach\"\"\"\n",
    "data1, sample_weight_col = dataprep.prepare_data4training_2(data, sound_levels, aul_sound_level)\n",
    "data1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:03:16.579546Z",
     "start_time": "2021-02-08T17:03:16.519566Z"
    }
   },
   "outputs": [],
   "source": [
    "main_label_col, freq_label_col, data_cols = dataprep.get_col_names4model_2_labels(data1)\n",
    "print('main label column [%s ... %s]' % (main_label_col[0], main_label_col[-1]))\n",
    "print('frequency label columns: [%s ... %s]' % (freq_label_col[0], freq_label_col[-1]))\n",
    "print('data columns: [%s ... %s]' % (data_cols[0], data_cols[-1]))\n",
    "\n",
    "print('sample weight column: %s' % sample_weight_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:03:19.546660Z",
     "start_time": "2021-02-08T17:03:19.485049Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Distinguish training, validation and testing data - determined by previous model\"\"\"\n",
    "\"\"\"Get indices\"\"\"\n",
    "train_indices = data1.index[data1['mouse_group'].isin(['train', 'valid'])]\n",
    "test_indices = data1.index[data1['mouse_group']=='test']\n",
    "\"\"\"Get mouse ids\"\"\"\n",
    "train_mice = data1.loc[train_indices, 'mouse_id'].unique()\n",
    "test_mice = data1.loc[test_indices, 'mouse_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold cross validationÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:03:27.516146Z",
     "start_time": "2021-02-08T17:03:27.460647Z"
    }
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:03:29.169792Z",
     "start_time": "2021-02-08T17:03:29.116793Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_name(k):\n",
    "    return 'model_2_'+str(k)+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:03:33.062876Z",
     "start_time": "2021-02-08T17:03:33.006990Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_weights_name(k):\n",
    "    return 'model_2_'+str(k)+'_weights.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:03:36.056240Z",
     "start_time": "2021-02-08T17:03:36.000353Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Import data generator\"\"\"\n",
    "from ABR_ThresholdFinder_NN.data_generator import DataGenerator\n",
    "\"\"\"Import callbacks\"\"\"\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:59:01.213595Z",
     "start_time": "2021-02-08T17:04:17.994926Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Perform cross validation\"\"\"\n",
    "VAL_RESULTS = {}\n",
    "fold_var = 1\n",
    "\n",
    "length_input = len(data_cols)\n",
    "\n",
    "\"\"\"Define criterion for early stopping\"\"\"\n",
    "mon_var = 'val_main_prediction_loss'\n",
    "\n",
    "for train_index, val_index in kf.split(train_mice):\n",
    "    \n",
    "    print('fold %d' % fold_var)\n",
    "    \n",
    "    _train_mice = train_mice[train_index]\n",
    "    _val_mice = train_mice[val_index]\n",
    "    print('Overlap train/validation: %s' % np.intersect1d(_train_mice, _val_mice))\n",
    "    \n",
    "    train_index = data1.index[data1['mouse_id'].isin(_train_mice)].values\n",
    "    val_index = data1.index[data1['mouse_id'].isin(_val_mice)].values\n",
    "    \n",
    "    print(train_index, val_index)\n",
    "    print()\n",
    "    \n",
    "    train_data_generator = DataGenerator(list_IDs=train_index, \n",
    "                                         df=data1, \n",
    "                                         value_cols=data_cols, \n",
    "                                         main_label_col=main_label_col, \n",
    "                                         freq_label_col=freq_label_col, \n",
    "                                         sl_label_col=[],\n",
    "                                         dim=length_input, \n",
    "                                         batch_size=batch_size, \n",
    "                                         shuffle=True,\n",
    "                                         sample_weight_col=sample_weight_col)\n",
    "    valid_data_generator = DataGenerator(list_IDs=val_index, \n",
    "                                         df=data1, \n",
    "                                         value_cols=data_cols, \n",
    "                                         main_label_col=main_label_col, \n",
    "                                         freq_label_col=freq_label_col, \n",
    "                                         sl_label_col=[],\n",
    "                                         dim=length_input, \n",
    "                                         batch_size=batch_size, \n",
    "                                         shuffle=True,\n",
    "                                         sample_weight_col=sample_weight_col)\n",
    "    \n",
    "    \"\"\"Create Model II\"\"\"\n",
    "    model = create_model_2(len(data_cols), len(main_label_col), len(freq_label_col))\n",
    "    \"\"\"Compile Model II\"\"\"\n",
    "    parallel_model, loss, loss_weights = compile_model_2(model, count_gpus)\n",
    "\n",
    "    \"\"\"Create callbacks\"\"\"\n",
    "    checkpoint = ModelCheckpoint(filepath=save_dir+get_model_weights_name(fold_var), \n",
    "                                 verbose=1, save_best_only=True, monitor=mon_var)\n",
    "    early_stopper = EarlyStopping(monitor=mon_var, patience=61)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=mon_var, patience=10)\n",
    "    callbacks_list = [checkpoint, early_stopper, reduce_lr]\n",
    "    \n",
    "    \"\"\"Fit the model\"\"\"\n",
    "    history = parallel_model.fit_generator(generator=train_data_generator,\n",
    "                                           validation_data=valid_data_generator, \n",
    "                                           use_multiprocessing=True, \n",
    "                                           epochs=200,\n",
    "                                           workers=8,\n",
    "                                           shuffle=True,\n",
    "                                           callbacks=callbacks_list)\n",
    "    \n",
    "    \"\"\"Plot history\"\"\"\n",
    "    \"\"\"Summarize history for loss\"\"\"\n",
    "    plt.figure(figsize=(20, 14), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    plt.plot(history.history['main_prediction_loss'])\n",
    "    plt.plot(history.history['val_main_prediction_loss'])\n",
    "    plt.title(get_model_name(fold_var) + ' main prediction loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.savefig(save_dir + \"/model_2_\" + str(fold_var) + \"_loss_history_.png\")\n",
    "    plt.show()\n",
    "\n",
    "    \"\"\"Summarize history for accuracy\"\"\"\n",
    "    plt.figure(figsize=(20, 14), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    plt.plot(history.history['main_prediction_categorical_accuracy'])\n",
    "    plt.plot(history.history['val_main_prediction_categorical_accuracy'])\n",
    "    plt.title(get_model_name(fold_var) + ' main prediction categorical accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='lower right')\n",
    "    plt.savefig(save_dir + \"/model_2_\" + str(fold_var) + \"_acc_history_.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    \"\"\"Load best model to evaluate the performance of the model\"\"\"\n",
    "    parallel_model.load_weights(save_dir + get_model_weights_name(fold_var))\n",
    "    model.save(save_dir + get_model_name(fold_var))\n",
    "    \n",
    "    results = parallel_model.evaluate(valid_data_generator)\n",
    "    results = dict(zip(parallel_model.metrics_names,results))\n",
    "\n",
    "    VAL_RESULTS[get_model_name(fold_var)] = results\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    fold_var+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T18:16:48.924425Z",
     "start_time": "2021-02-08T18:16:48.796648Z"
    }
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns=['model'])\n",
    "for idx,model in enumerate(VAL_RESULTS):\n",
    "    df_results.loc[idx, 'model'] = model \n",
    "    for metric in VAL_RESULTS[model]:\n",
    "        df_results.loc[idx, metric] = VAL_RESULTS[model][metric]\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T18:16:51.027618Z",
     "start_time": "2021-02-08T18:16:50.967785Z"
    }
   },
   "outputs": [],
   "source": [
    "print('loss: %.2f' % df_results.loss.mean())\n",
    "print(' main prediction loss: %.2f' % df_results.main_prediction_loss.mean())\n",
    "print(' frequency prediction loss: %.2f' % df_results.frequency_prediction_loss.mean())\n",
    "print()\n",
    "print('main prediction categorical accuracy: %.2f' % df_results.main_prediction_categorical_accuracy.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T18:18:41.372743Z",
     "start_time": "2021-02-08T18:16:59.960025Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data_generator = DataGenerator(list_IDs=test_indices, \n",
    "                                    df=data1, \n",
    "                                    value_cols=data_cols, \n",
    "                                    main_label_col=main_label_col, \n",
    "                                    freq_label_col=freq_label_col, \n",
    "                                    sl_label_col=[],\n",
    "                                    dim=length_input, \n",
    "                                    batch_size=batch_size, \n",
    "                                    sample_weight_col=sample_weight_col)\n",
    "\n",
    "TST_RESULTS = {}\n",
    "for fold_var in range(1, 6):\n",
    "    \n",
    "    print(fold_var)\n",
    "    \n",
    "    # Load model for testing\n",
    "    parallel_model = tf.keras.models.load_model(save_dir + get_model_weights_name(fold_var))\n",
    "   \n",
    "    # Evaluate model on test data    \n",
    "    results = parallel_model.evaluate(test_data_generator)\n",
    "    results = dict(zip(parallel_model.metrics_names,results))\n",
    "    \n",
    "    TST_RESULTS[get_model_name(fold_var)] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T18:19:29.327801Z",
     "start_time": "2021-02-08T18:19:29.249630Z"
    }
   },
   "outputs": [],
   "source": [
    "df_results1 = pd.DataFrame(columns=['model'])\n",
    "for idx,model in enumerate(TST_RESULTS):\n",
    "    df_results1.loc[idx, 'model'] = model \n",
    "    for metric in TST_RESULTS[model]:\n",
    "        df_results1.loc[idx, metric] = TST_RESULTS[model][metric]\n",
    "df_results1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T18:19:34.214848Z",
     "start_time": "2021-02-08T18:19:34.154609Z"
    }
   },
   "outputs": [],
   "source": [
    "print('loss: %.2f' % df_results1.loss.mean())\n",
    "print(' main prediction loss: %.2f' % df_results1.main_prediction_loss.mean())\n",
    "print(' frequency prediction loss: %.2f' % df_results1.frequency_prediction_loss.mean())\n",
    "print()\n",
    "print('main prediction categorical accuracy: %.2f' % df_results1.main_prediction_categorical_accuracy.mean())"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
