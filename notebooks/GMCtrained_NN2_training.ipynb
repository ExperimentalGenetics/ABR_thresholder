{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This notebook is used to train **Model II** based on data provided by the [German Mouse Clinic](https://www.mouseclinic.de/). \n",
    "\n",
    "Model II is trained as classifier for every stimulus to predict the hearing threshold using the respective class score outputs of Model I as input and the original hearing thresholds as labels.\n",
    "\n",
    "**A hearing threshold is defined as the lowest sound level at which the mouse can still hear something**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T13:13:53.017753Z",
     "start_time": "2021-02-08T13:13:52.743061Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-24T09:14:34.769060Z",
     "start_time": "2021-02-24T09:14:33.163820Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [20, 16]\n",
    "\n",
    "import ABR_ThresholdFinder_NN.data_preparation as dataprep\n",
    "from ABR_ThresholdFinder_NN.models import create_model_1, compile_model_1, create_model_2, compile_model_2\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\"\"\"Set the available GPUs\"\"\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "count_gpus = len([int(s) for s in os.environ['CUDA_VISIBLE_DEVICES'].split(',')])\n",
    "print('%d GPUS' % count_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T13:14:00.047550Z",
     "start_time": "2021-02-08T13:13:59.983134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potential sound pressure levels [dB]: 0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Set the batch size\"\"\"\n",
    "batch_size=128\n",
    "\n",
    "\"\"\"Set the cutoff for the hearing threshold\"\"\"\n",
    "threshold_cutoff = 0.5\n",
    "\n",
    "\"\"\"Initialize the sample weight column (for the main label) \"\"\"\n",
    "sample_weight_col = []\n",
    "\n",
    "\"\"\"Define potential sound pressure levels measured in dB\"\"\"\n",
    "sound_levels = [x for x in range(0, 100, 5)] \n",
    "print(*['potential sound pressure levels [dB]: ' + str(x) if x==0 else str(x) for x in sound_levels], sep = \", \") \n",
    "aul_sound_level = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:06:42.525363Z",
     "start_time": "2021-02-05T17:06:42.465564Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Set the path to the data files\"\"\"\n",
    "save_dir = '../models/'\n",
    "data_file = os.path.join(save_dir, 'GMCtrained_model_1_predicted_curves.csv')\n",
    "if os.path.exists(data_file):\n",
    "    print('data file: {}'.format(data_file))\n",
    "else: \n",
    "    print('ERROR: data file not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:06:44.307499Z",
     "start_time": "2021-02-05T17:06:44.059321Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Load data from file, which is the output of Model I\"\"\"\n",
    "data = pd.read_csv(data_file)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:06:55.054075Z",
     "start_time": "2021-02-05T17:06:52.493101Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Prepare the data to feed the second convolutional neural network\"\"\"\n",
    "data1, sample_weight_col = dataprep.prepare_data4training_2(data, sound_levels, aul_sound_level)\n",
    "data1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:07:01.670048Z",
     "start_time": "2021-02-05T17:07:01.609367Z"
    }
   },
   "outputs": [],
   "source": [
    "main_label_col, freq_label_col, data_cols = dataprep.get_col_names4model_2_labels(data1)\n",
    "print('main label column [%s ... %s]' % (main_label_col[0], main_label_col[-1]))\n",
    "print('frequency label columns: [%s ... %s]' % (freq_label_col[0], freq_label_col[-1]))\n",
    "print('data columns: [%s ... %s]' % (data_cols[0], data_cols[-1]))\n",
    "\n",
    "print('sample weight column: %s' % sample_weight_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:07:08.170199Z",
     "start_time": "2021-02-05T17:07:08.102314Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Distinguish training, validation and testing data - determined by previous model\"\"\"\n",
    "\"\"\"Get indices\"\"\"\n",
    "train_indices = data1.index[data1['mouse_group']=='train']\n",
    "valid_indices = data1.index[data1['mouse_group']=='valid']\n",
    "test_indices = data1.index[data1['mouse_group']=='test']\n",
    "\"\"\"Get mouse IDs\"\"\"\n",
    "train_mice = data1.loc[train_indices, 'mouse_id']\n",
    "valid_mice = data1.loc[valid_indices, 'mouse_id']\n",
    "test_mice = data1.loc[test_indices, 'mouse_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:07:23.422144Z",
     "start_time": "2021-02-05T17:07:23.365519Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Import the data generator\"\"\"\n",
    "import ABR_ThresholdFinder_NN.data_generator as datagenerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:07:29.498320Z",
     "start_time": "2021-02-05T17:07:29.436705Z"
    }
   },
   "outputs": [],
   "source": [
    "length_input = len(data_cols)\n",
    "\n",
    "train_data_generator = datagenerate.DataGenerator(list_IDs=train_indices,\n",
    "                                     df=data1, \n",
    "                                     value_cols=data_cols, \n",
    "                                     main_label_col=main_label_col, \n",
    "                                     freq_label_col=freq_label_col, \n",
    "                                     sl_label_col=[], \n",
    "                                     dim=length_input, \n",
    "                                     batch_size=batch_size, \n",
    "                                     shuffle=True,\n",
    "                                     sample_weight_col=sample_weight_col)\n",
    "valid_data_generator = datagenerate.DataGenerator(list_IDs=valid_indices,\n",
    "                                     df=data1, \n",
    "                                     value_cols=data_cols, \n",
    "                                     main_label_col=main_label_col, \n",
    "                                     freq_label_col=freq_label_col, \n",
    "                                     sl_label_col=[], \n",
    "                                     dim=length_input, \n",
    "                                     batch_size=batch_size, \n",
    "                                     shuffle=True,\n",
    "                                     sample_weight_col=sample_weight_col)\n",
    "test_data_generator = datagenerate.DataGenerator(list_IDs=test_indices,\n",
    "                                    df=data1, \n",
    "                                    value_cols=data_cols, \n",
    "                                    main_label_col=main_label_col, \n",
    "                                    freq_label_col=freq_label_col, \n",
    "                                    sl_label_col=[], \n",
    "                                    dim=length_input, \n",
    "                                    batch_size=batch_size, \n",
    "                                    sample_weight_col=sample_weight_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:07:47.893093Z",
     "start_time": "2021-02-05T17:07:47.503444Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Create Model II\"\"\"\n",
    "model = create_model_2(len(data_cols), len(main_label_col), len(freq_label_col))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:07:54.044380Z",
     "start_time": "2021-02-05T17:07:51.699291Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Compile Model II\"\"\"\n",
    "parallel_model, loss, loss_weights = compile_model_2(model, count_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:08:07.436880Z",
     "start_time": "2021-02-05T17:08:07.380011Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Import callbacks\"\"\"\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:21:20.687605Z",
     "start_time": "2021-02-05T17:08:52.606562Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Define criterion for early stopping\"\"\"\n",
    "mon_var = 'val_main_prediction_loss'\n",
    "\n",
    "\"\"\"Create callbacks\"\"\"\n",
    "checkpoint = ModelCheckpoint(filepath=save_dir + 'GMCtrained_model_2_weights.hdf5', \n",
    "                             verbose=1, save_best_only=True, monitor=mon_var)\n",
    "early_stopper = EarlyStopping(monitor=mon_var, patience=61)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=mon_var, patience=10)\n",
    "callbacks_list = [checkpoint, early_stopper, reduce_lr]\n",
    "\n",
    "\"\"\"Fit Model II\"\"\"\n",
    "history = parallel_model.fit_generator(generator=train_data_generator, \n",
    "                                       validation_data=valid_data_generator, \n",
    "                                       use_multiprocessing=True, \n",
    "                                       epochs=200,\n",
    "                                       workers=8,\n",
    "                                       shuffle=True,\n",
    "                                       callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:43:53.193652Z",
     "start_time": "2021-02-05T17:43:52.369027Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot history\"\"\"\n",
    "\"\"\"Summarize history for loss\"\"\"\n",
    "plt.figure(figsize=(20, 14), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.plot(history.history['main_prediction_loss'])\n",
    "plt.plot(history.history['val_main_prediction_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.savefig(save_dir + \"GMCtraining_history/GMCtrained_model_2_loss_history.png\")\n",
    "plt.show()\n",
    "\n",
    "\"\"\"Summarize history for accuracy\"\"\"\n",
    "plt.figure(figsize=(20, 14), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.plot(history.history['main_prediction_categorical_accuracy'])\n",
    "plt.plot(history.history['val_main_prediction_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='lower right')\n",
    "plt.savefig(save_dir + \"GMCtraining_history/GMCtrained_model_2_acc_history.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation on test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:44:31.125270Z",
     "start_time": "2021-02-05T17:44:20.640962Z"
    }
   },
   "outputs": [],
   "source": [
    "results = parallel_model.evaluate(test_data_generator)\n",
    "results = dict(zip(parallel_model.metrics_names,results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:47:00.581292Z",
     "start_time": "2021-02-05T17:47:00.521381Z"
    }
   },
   "outputs": [],
   "source": [
    "for metric in results: \n",
    "    print('%s: %.2f' % (metric, results[metric]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save non-GPU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:47:09.784700Z",
     "start_time": "2021-02-05T17:47:08.938243Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(save_dir + 'GMCtrained_model_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:47:13.683328Z",
     "start_time": "2021-02-05T17:47:12.715030Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Load model for predictions and validation\"\"\"\n",
    "from tensorflow.keras.models import load_model\n",
    "parallel_model = load_model(save_dir + 'GMCtrained_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:47:17.553279Z",
     "start_time": "2021-02-05T17:47:17.488299Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = data1[data1.mouse_id.isin(test_mice)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:47:23.432294Z",
     "start_time": "2021-02-05T17:47:22.476906Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Make predictions for the test dataset\"\"\"\n",
    "df = parallel_model.predict(test_data[data_cols].values[:,:,np.newaxis])\n",
    "predictions = pd.concat([pd.DataFrame(df[0]), pd.DataFrame(df[1])], axis=1, ignore_index=True)\n",
    "\n",
    "\"\"\"Define column names of predictions\"\"\"\n",
    "predictions.columns = main_label_col + freq_label_col\n",
    "predictions.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:47:57.801782Z",
     "start_time": "2021-02-05T17:47:50.557108Z"
    }
   },
   "outputs": [],
   "source": [
    "thr_estimations = pd.DataFrame()\n",
    "for idx in predictions.index:\n",
    "    thr_preds = predictions.loc[idx, main_label_col]\n",
    "    thr_preds = thr_preds.iloc[thr_preds.values == min(thr_preds.iloc[thr_preds.values > threshold_cutoff])]\n",
    "    thr_estimations.loc[idx, 'pred_thr'] = thr_preds.index[0]\n",
    "    thr_estimations.loc[idx, 'pred_score'] = thr_preds.values[0]\n",
    "    \n",
    "print(thr_estimations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:47:38.536315Z",
     "start_time": "2021-02-05T17:47:37.473222Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data1 = test_data.copy()\n",
    "\n",
    "\"\"\"Based on the defined cutoff, determine the threshold from the prediction values\"\"\"\n",
    "\n",
    "\"\"\"Apply cutoff\"\"\"\n",
    "a = predictions[main_label_col].where(predictions[main_label_col] > threshold_cutoff).notna()\n",
    "a = a[a==True]\n",
    "\n",
    "\"\"\"Save encoded value in the new dataframe\"\"\"\n",
    "test_data1['predicted_thr_encoded'] = a.apply(lambda x: x[x.notnull()].index.values[-1], axis=1)\n",
    "\n",
    "\"\"\"Decode the threshold with dictionary\"\"\"\n",
    "test_data1['predicted_thr'] = test_data1['predicted_thr_encoded'].str.replace(r'\\D+', '').astype('int')\n",
    "_temp = [aul_sound_level] + sorted(sound_levels, reverse=True)\n",
    "thresh_dict = dict(zip(_temp, list(range(len(_temp)))))\n",
    "inv_thresh_dict = {v: k for k, v in thresh_dict.items()}\n",
    "test_data1['predicted_thr'] = test_data1['predicted_thr'].map(inv_thresh_dict)\n",
    "\n",
    "\"\"\"Decode and save frequency prediction\"\"\"\n",
    "test_data1['predicted_freq_encoded'] = predictions.loc[:, freq_label_col].idxmax(axis=1)\n",
    "test_data1['predicted_freq'] = test_data1['predicted_freq_encoded'].str.replace(r'\\D+', '').astype('int')\n",
    "_temp = sorted(test_data1['frequency'].unique())\n",
    "freq_dict = dict(zip(_temp, list(range(len(_temp)))))\n",
    "inv_freq_dict = {v: k for k, v in freq_dict.items()}\n",
    "test_data1['predicted_freq'] = test_data1['predicted_freq'].map(inv_freq_dict)\n",
    "test_data1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:51:27.348202Z",
     "start_time": "2021-02-05T17:51:27.206089Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data1['prediction_score'] = [thr_estimations.loc[idx, 'pred_score'] for idx in test_data1.index]\n",
    "test_data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:51:32.954800Z",
     "start_time": "2021-02-05T17:51:32.806940Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Output overall mouse metrics\"\"\"\n",
    "\n",
    "\"\"\"Select only test mice\"\"\"\n",
    "result_test = test_data1.loc[(test_data1['mouse_id'].isin(test_mice))].copy()# & (test_data1['swipe']=='right')].copy()\n",
    "result_test = result_test.sort_values(by='frequency')\n",
    "\n",
    "\"\"\"Compute distance to actual threshold\"\"\"\n",
    "result_test['thr_dist'] = result_test.threshold - result_test.predicted_thr\n",
    "\n",
    "\"\"\"Print frequency accuracy\"\"\"\n",
    "freq_acc = 100 * round(len(result_test[result_test['frequency'] == result_test['predicted_freq']]) / \n",
    "                       len(result_test), 3)\n",
    "print('Frequency accuracy: %.2f%%' % freq_acc)\n",
    "print()\n",
    "\n",
    "\"\"\"Print exact accuracy of main label prediction\"\"\"\n",
    "thr_acc = 100 * round(len(result_test[result_test.threshold==result_test['predicted_thr']]) / \n",
    "                  len(result_test), 3)\n",
    "print('threshold accuracy: %.2f%%' % thr_acc)\n",
    "for freq in result_test.frequency.unique():\n",
    "    freq_thr_acc = 100 * round(len(result_test[(result_test.threshold==result_test.predicted_thr) & (result_test.frequency==freq)]) / \n",
    "                               len(result_test[result_test.frequency==freq]), 3)\n",
    "    if freq == 100: \n",
    "        print(\"   Click: %.2f%%\" % freq_thr_acc)\n",
    "    else:\n",
    "        print(\"   Frequency %d: %.2f%%\" % (freq, freq_thr_acc))\n",
    "\n",
    "\"\"\"Print error of main label prediction\"\"\"\n",
    "all_me = round(np.mean(abs(result_test.threshold - result_test.predicted_thr)), 3)\n",
    "print('Mean error of all classifications: %.2f' % all_me)\n",
    "\n",
    "\"\"\"Print only error of wrong classifications\"\"\"\n",
    "f_mae = round(np.mean(abs(result_test[result_test.threshold!=result_test.predicted_thr].threshold - \n",
    "                          result_test[result_test.threshold!=result_test.predicted_thr].predicted_thr)), 3)\n",
    "print(\"Absolute mean error of false classifications: %.2f\" % f_mae)\n",
    "for freq in result_test.frequency.unique():\n",
    "    freq_f_mae = round(np.mean(abs(result_test[(result_test.threshold!=result_test.predicted_thr) & (result_test.frequency==freq)].threshold - \n",
    "                                   result_test[(result_test.threshold!=result_test.predicted_thr) & (result_test.frequency==freq)].predicted_thr)), 3)\n",
    "    freq_mae = round(np.mean(abs(result_test[result_test.frequency==freq].threshold - \n",
    "                                 result_test[result_test.frequency==freq].predicted_thr)), 3)\n",
    "    if freq == 100:\n",
    "        print('   Click: %.2f (%.2f)' % (freq_f_mae, freq_mae))\n",
    "    else: \n",
    "        print('   Frequency %d: %.2f (%.2f)' % (freq, freq_f_mae, freq_mae))\n",
    "\n",
    "\"\"\"Print accuracy with 5 dB buffer\"\"\"\n",
    "prop_mice_5db = 100 * round(len(result_test[abs(result_test.thr_dist)<=5]) / len(result_test), 3)\n",
    "print('Proportion of mice with deviations of maximum 5dB: %.2f%%' % prop_mice_5db)\n",
    "for freq in result_test.frequency.unique():\n",
    "    freq_prop_mice_5db = 100 * round(len(result_test[(abs(result_test.thr_dist)<=5) & (result_test.frequency==freq)]) / \n",
    "                                     len(result_test[result_test.frequency==freq]), 3)\n",
    "    freq_count = len(result_test[result_test.frequency==freq])    \n",
    "    if freq == 100: \n",
    "        print('   Click: %.2f%% (%d)' % (freq_prop_mice_5db, freq_count))\n",
    "    else:\n",
    "        print('   Frequency %d: %.2f%% (%d)' % (freq, freq_prop_mice_5db, freq_count))\n",
    "    \n",
    "\"\"\"Print accuracy with 10 dB buffer\"\"\"\n",
    "prop_mice_10db = 100 * round(len(result_test[abs(result_test.thr_dist)<=10]) / len(result_test), 3)\n",
    "print('Proportion of mice with deviations of maximum 10dB: %.2f%%' % prop_mice_5db)\n",
    "for freq in result_test.frequency.unique():\n",
    "    freq_prop_mice_10db = 100 * round(len(result_test[(abs(result_test.thr_dist)<=10) & (result_test.frequency==freq)]) / \n",
    "                                      len(result_test[result_test.frequency==freq]), 3)\n",
    "    freq_count = len(result_test[result_test.frequency==freq])\n",
    "    if freq == 100: \n",
    "        print('   Click: %.2f%% (%d)' % (freq_prop_mice_10db, freq_count))\n",
    "    else:\n",
    "        print('   Frequency %d: %.2f%% (%d)' % (freq, freq_prop_mice_10db, freq_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot threshold deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:51:48.069251Z",
     "start_time": "2021-02-05T17:51:47.940081Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T17:51:50.988423Z",
     "start_time": "2021-02-05T17:51:49.399812Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Confusion matrix for all frequencies\"\"\"\n",
    "result_test2 = result_test\n",
    "confusion_mtx = confusion_matrix(result_test2['threshold'], result_test2['predicted_thr']) \n",
    "index = [int(x) for x in sorted(result_test2['threshold'].unique())]\n",
    "print('threshold', index, len(index))\n",
    "print()\n",
    "columns = [int(x) for x in sorted(result_test2['predicted_thr'].unique())]\n",
    "print('predicted threshold', columns, len(columns))\n",
    "print()\n",
    "merged_list = list(itertools.chain(*itertools.zip_longest(result_test2['threshold'].unique(), \n",
    "                                                          result_test2['predicted_thr'].unique())))\n",
    "merged_list = [i for i in merged_list if i is not None]\n",
    "merged_list = sorted(set(merged_list))\n",
    "print(merged_list)\n",
    "confusion_mtx = pd.DataFrame(confusion_mtx, index = merged_list, \n",
    "                             columns = merged_list)\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.figure(figsize=(20,16))\n",
    "\n",
    "ax = sns.heatmap(confusion_mtx, annot=True, fmt=\"d\", cmap='Spectral_r', center=210)\n",
    "ax.set(xlabel='Predicted threshold', ylabel='Manual threshold')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}