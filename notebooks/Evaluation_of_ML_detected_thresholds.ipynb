{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This notebook is used to evaluate the hearing thresholds predicted by neural networks (NN) or estimated by a sound level regression method (SLR) by comparison with a ground truth which are manually assessed thresholds.\n",
    "\n",
    "Different evaluation approaches are used to compare machine-determined hearing thresholds with the ground truth corresponding to manually assessed thresholds.</br>\n",
    "For this, a series of experiments are done in which the two different ABR threshold finding methods (NN and SLR) were tested on [GMC](https://www.mouseclinic.de/) and [ING](https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000194) data sets:\n",
    "1. **NN GMC-GMC**: NN trained on GMC data and tested on GMC data\n",
    "2. NN GMC-ING: NN trained on GMC data and tested on ING data\n",
    "3. NN ING-GMC: NN trained on ING data and tested on GMC data\n",
    "4. **NN ING-ING**: NN trained on ING data and tested on ING data\n",
    "5. **SLR GMC-GMC**: SLR calibrated on GMC data and tested on GMC data\n",
    "6. SLR GMC-ING: SLR calibrated on GMC data and tested on ING data\n",
    "7. SLR ING-GMC: SLR calibrated on ING data and tested on GMC data\n",
    "8. **SLR ING-ING**: SLR calibrated on ING data and tested on ING data\n",
    "\n",
    "Furthermore, evaluation curves are calculated and plotted to enable an estimation of the quality of thresholding.</br>\n",
    "**Evaluation curves** allow the relative comparison of threshold finding methods without requiring absolute ground truth labels. For this, four experiments are done to manual thresholds (blue, dotted lines), SLR estimations (<font color='red'>**red**</font>, dashed lines), NN predictions (<font color='green'>**green**</font>, dash-dotted lines), and a ”always 50 dB” dummy method (<font color='grey'>**grey**</font>, solid lines).\n",
    "1. **NN GMC-GMC, SLR GMC-GMC, GMC manual thresholds, dummy method**\n",
    "2. NN GMC-ING, SLR GMC-ING, ING manual thresholds, dummy method\n",
    "3. NN ING-GMC, SLR ING-GMC, GMC manual thresholds, dummy method\n",
    "4. **NN ING-ING, SLR ING-ING, ING manual thresholds, dummy method**\n",
    "\n",
    "Following files were used: \n",
    "\n",
    "* Files with ABR curves and the manually assessed thresholds per stimulus:\n",
    "    * GMC data: _GMC_abr_curves.csv_\n",
    "    * ING data: _ING_abr_curves.csv_\n",
    "\n",
    "* Files with thresholds predicted by neural networks: \n",
    "    * NN GMC-GMC: _../results/GMC_data_GMCtrained_NN_predictions.csv_\n",
    "    * NN GMC-ING: _../results/ING_data_GMCtrained_NN_predictions.csv_\n",
    "    * NN ING-GMC: _../results/GMC_data_INGtrained_NN_predictions.csv_\n",
    "    * NN ING-ING: _../results/ING_data_INGtrained_NN_predictions.csv_\n",
    "    \n",
    "* Files with thresholds estimated by a sound level regression method: \n",
    "    * SLR GMC-GMC: _../results/GMC_data_GMCcalibrated_SLR_estimations.csv_\n",
    "    * SLR GMC-ING: _../results/ING_data_GMCcalibrated_SLR_estimations.csv_\n",
    "    * SLR ING-GMC: _../results/GMC_data_INGcalibrated_SLR_estimations.csv_\n",
    "    * SLR ING-ING: _../results/ING_data_INGcalibrated_SLR_estimations.csv_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T08:51:46.353524Z",
     "start_time": "2021-05-07T08:51:45.930030Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T08:51:46.983285Z",
     "start_time": "2021-05-07T08:51:46.955875Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T09:07:11.610966Z",
     "start_time": "2021-05-07T09:07:11.095614Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import ABR_ThresholdFinder_NN.data_preparation as dataprep\n",
    "import ABR_ThresholdFinder_NN.thresholder as abrthr\n",
    "\n",
    "from ABR_ThresholdFinder_SLR.evaluations import plot_evaluation_curve_for_specific_stimulus\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.ticker as ticker\n",
    "plt.rcParams['figure.figsize'] = [10, 8]\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, recall_score, f1_score, r2_score\n",
    "from sklearn.metrics import auc, average_precision_score, precision_recall_curve, plot_precision_recall_curve, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import itertools\n",
    "\n",
    "import scipy.stats as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T08:51:56.671206Z",
     "start_time": "2021-05-07T08:51:56.606606Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Set the path to the data files, for example '../data'\"\"\"\n",
    "path2data = '../data/'\n",
    "\"\"\"Set the path to result data\"\"\"\n",
    "path2results = '../results/'\n",
    "\"\"\"Name the time step columns\"\"\"\n",
    "datacols = ['t' + str(i) for i in range(0, 1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T07:54:37.984332Z",
     "start_time": "2021-05-03T07:54:37.919124Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_standardised_error(_data, _manual_thr_col, _pred_thr_col, \n",
    "                            _xlabel, _ylabel, _title, _freq_specific=False, \n",
    "                            _hue=None, _fontsize=30, _figsize=(30,15)):\n",
    "    \"\"\"\n",
    "    Plots the error of the automatically determined threshold values normalised to the \n",
    "    variance of the manually determined threshold values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        _data: pandas-data-frame\n",
    "            It contains both manually assessed and automatically determined thresholds for each mouse identifier \n",
    "            and hearing stimulus. \n",
    "            \n",
    "        _manual_thr_col: string\n",
    "            The name of the column in which the manually assessed thresholds are stored.\n",
    "            \n",
    "        _pred_thr_col: string \n",
    "            The name of the column in which the automatically determined thresholds are stored.\n",
    "            \n",
    "        _freq_specific: boolean\n",
    "            If true error is plotted for each stimulus separately.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    df = _data.copy()\n",
    "    for col in [_manual_thr_col, _pred_thr_col]:\n",
    "        df[col] = [100 if df.loc[idx, col] == 999 else df.loc[idx, col] for idx in df.index]\n",
    "    \n",
    "    df['thr_diff'] = abs(df[_pred_thr_col] - df[_manual_thr_col])\n",
    "    var = np.var(df[_manual_thr_col])\n",
    "    df['thr_diff'] = df['thr_diff']/var\n",
    "    \n",
    "    if _freq_specific:\n",
    "        frequencies = df.frequency.unique()\n",
    "\n",
    "        rows = 3\n",
    "        cols = 2\n",
    "    \n",
    "        col = 0\n",
    "        row = 0\n",
    "\n",
    "        fig, axes = plt.subplots(ncols=cols, nrows=rows, #gridspec_kw={'wspace': 5},\n",
    "                                 sharey=True, sharex=True, figsize=_figsize, constrained_layout=True)\n",
    "        \n",
    "        for idx, freq in enumerate(sorted(frequencies)):\n",
    "            \n",
    "            sns.histplot(data=df[df.frequency == freq], x=\"thr_diff\", stat=\"percent\", # \"count\",\n",
    "                         palette=sns.color_palette(\"colorblind\"), bins=35, ax=axes[row,col])\n",
    "            \n",
    "            axes[row,col].set_yticks([x for x in range(10,110,10)])\n",
    "            axes[row,col].set_ylim(0,100)\n",
    "            \n",
    "            axes[row,col].set_xticks([x for x in np.arange(0,0.35,0.05)])\n",
    "            axes[row,col].set_xlim(0,0.3)\n",
    "            \n",
    "            axes[row,col].set_xticklabels([\"{:.2f}\".format(xtick) for xtick in axes[row,col].get_xticks()], fontsize=_fontsize-10)\n",
    "            axes[row,col].set_yticklabels(['%d%%' % ytick for ytick in axes[row,col].get_yticks()], fontsize=_fontsize-10)\n",
    "\n",
    "            if col == 0:\n",
    "                axes[row,col].set_ylabel(_ylabel, fontsize=_fontsize, labelpad=15)\n",
    "            if row == rows-1:\n",
    "                axes[row,col].set_xlabel(_xlabel, fontsize=_fontsize, labelpad=15)\n",
    "            if freq == 100:\n",
    "                axes[row,col].set_title('Click', fontsize=_fontsize, pad=15)\n",
    "            else:\n",
    "                axes[row,col].set_title('%d kHz' % (freq/1000), fontsize=_fontsize, pad=15)\n",
    "    \n",
    "            col += 1\n",
    "            if col == cols:\n",
    "                row += 1\n",
    "                col = 0\n",
    "        plt.suptitle(_title, fontsize=_fontsize)\n",
    "    else:\n",
    "        plt.figure(figsize=_figsize)\n",
    "        ax = sns.histplot(data=df, x=\"thr_diff\", stat=\"percent\", # \"count\", \n",
    "                          palette=sns.color_palette(\"colorblind\"), bins=35, hue=_hue)\n",
    "        ax.set_yticks([x for x in range(0,110,10)])\n",
    "        ax.set_ylim(0,100)\n",
    "        \n",
    "        ax.set_xticklabels([\"{:.2f}\".format(xtick) for xtick in ax.get_xticks()], fontsize=_fontsize-10)\n",
    "        ax.set_yticklabels(['%d%%' % ytick for ytick in ax.get_yticks()], fontsize=_fontsize-10)\n",
    "#         ax.set_yticklabels([int(ytick) for ytick in ax.get_yticks()], fontsize=_fontsize-10)\n",
    "        \n",
    "        ax.set_xlabel(_xlabel, fontsize=_fontsize)\n",
    "        ax.set_ylabel(_ylabel, fontsize=_fontsize)\n",
    "        ax.set_title(_title, fontsize=_fontsize, pad=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T06:55:32.304386Z",
     "start_time": "2021-05-03T06:55:32.237403Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_median(_data, _column, _title=None, _fontsize=30, _figsize=(30,30)):\n",
    "    \n",
    "    \"\"\"\n",
    "    Plots the medians of the automatically determined against the manually assessed thresholds.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        _data: pandas-data-frame\n",
    "            It contains both manually assessed and automatically determined thresholds for each mouse identifier \n",
    "            and hearing stimulus. \n",
    "            \n",
    "        _column: string\n",
    "            The name of the column in which the automatically determined thresholds are stored.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = _data.copy()\n",
    "    \n",
    "    fig = plt.figure(figsize=_figsize)\n",
    "    \n",
    "    fontsize = _fontsize\n",
    "\n",
    "    ax = sns.lineplot(data=df, x='threshold', y=_column, estimator=np.median, \n",
    "                      ci=None, marker='o', markersize=15, palette=sns.color_palette(\"colorblind\"), legend='auto')    \n",
    "        \n",
    "    ax.set_yticks([x for x in range(0,110,5)])\n",
    "    ax.set_ylim(0,100)\n",
    "    ax.set_xticks([x for x in range(0,110,5)])\n",
    "    ax.set_xlim(0,105)\n",
    "        \n",
    "    ax.set_xticklabels(ax.get_xticks(), fontsize=fontsize-10)\n",
    "    ax.set_yticklabels(ax.get_yticks(), fontsize=fontsize-10)\n",
    "        \n",
    "    if _title:\n",
    "        ax.set_title(_title, fontsize=fontsize+5, pad=20)\n",
    "    ax.set_xlabel('Manual threshold', fontsize=fontsize, labelpad=15)\n",
    "    ax.set_ylabel('NN predicted threshold' if 'nn' in _column else 'SLR estimated threshold', fontsize=fontsize, labelpad=15)\n",
    "          \n",
    "    bounds = df.groupby('threshold')[_column].quantile((0.25,0.75)).unstack()\n",
    "    ax.fill_between(x=bounds.index, y1=bounds.iloc[:,0], y2=bounds.iloc[:,1], alpha=0.1)\n",
    "    #ax.text(1, 95.5, 'median values and the interquartile range of the NN predicted thresholds', fontsize=fontsize-10)\n",
    "    \n",
    "    fig.legend(['median values and the interquartile range of the NN predicted thresholds'], loc='lower left', bbox_to_anchor= (0.065, 1.0), \n",
    "               borderaxespad=0, frameon=True, fontsize=fontsize-10)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T06:55:33.058481Z",
     "start_time": "2021-05-03T06:55:32.995548Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def plot_median_stimulus_specific(_data, _column, _title=None,  _fontsize=30, _figsize=(30,15)):\n",
    "    \n",
    "    \"\"\"\n",
    "    Plots the medians of the automatically determined thresholds against the manually assessed thresholds \n",
    "    for each stimulus separately.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        _data: pandas-data-frame\n",
    "            It contains both manually assessed and automatically determined thresholds for each mouse identifier \n",
    "            and hearing stimulus. \n",
    "            \n",
    "        _column: string\n",
    "            The name of the column in which the automatically determined thresholds are stored.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = _data\n",
    "    \n",
    "    cols = 2\n",
    "    rows = 3\n",
    "\n",
    "    row = 0\n",
    "    col = 0\n",
    "    \n",
    "    fig, axes = plt.subplots(ncols=cols, nrows=rows, sharey=True, sharex=True, \n",
    "                             figsize=_figsize, constrained_layout=True)\n",
    "    fontsize = _fontsize\n",
    "\n",
    "    for freq in df.frequency.unique():\n",
    "    \n",
    "        axes[row, col].set_yticks([x for x in range(0,110,5)])\n",
    "        axes[row, col].set_ylim(0,100)\n",
    "        axes[row, col].set_xticks([x for x in range(0,110,5)])\n",
    "        axes[row, col].set_xlim(0,105)\n",
    "        \n",
    "        axes[row, col].set_xticklabels(axes[row, col].get_xticks(), fontsize=fontsize-10)\n",
    "        axes[row, col].set_yticklabels(axes[row, col].get_yticks(), fontsize=fontsize-10)\n",
    "    \n",
    "        if freq == 100:\n",
    "            axes[row, col].set_title('Click', fontsize=fontsize+5, pad=20)\n",
    "        else:\n",
    "            axes[row, col].set_title('%dkHz' % int(freq/1000), fontsize=fontsize, pad=20)\n",
    "        if row == rows-1:\n",
    "            axes[row, col].set_xlabel('Manual threshold', fontsize=fontsize, labelpad=15)\n",
    "        else:\n",
    "            axes[row, col].set_xlabel('')\n",
    "        if col == 0:\n",
    "            axes[row, col].set_ylabel('NN predicted threshold' if 'nn' in _column else 'SLR estimated threshold', fontsize=fontsize)\n",
    "            \n",
    "        else:\n",
    "            axes[row, col].set_ylabel('')\n",
    "    \n",
    "        # line plot\n",
    "        sns.lineplot(data=df.loc[df.frequency==freq], \n",
    "                     x='threshold', y=_column, \n",
    "                     estimator=np.median, ci=None, marker='o', markersize=15, ax=axes[row, col], \n",
    "                     palette=sns.color_palette(\"colorblind\"))\n",
    "        \n",
    "        bounds = df.loc[df.frequency==freq].groupby('threshold')[_column].quantile((0.25,0.75)).unstack()\n",
    "        axes[row, col].fill_between(x=bounds.index, y1=bounds.iloc[:,0], y2=bounds.iloc[:,1], alpha=0.1)\n",
    "        \n",
    "        col += 1\n",
    "        if col == cols:\n",
    "            row += 1\n",
    "            col = 0 \n",
    "    if _title:\n",
    "        fig.suptitle(_title, fontsize=fontsize)\n",
    "    \n",
    "    fig.legend(['median values and the interquartile range of the NN predicted thresholds'], loc='lower left', bbox_to_anchor= (0.035, 1.01), \n",
    "               borderaxespad=0, frameon=True, fontsize=fontsize)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T06:55:33.761241Z",
     "start_time": "2021-05-03T06:55:33.703190Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(_data, _column, _title=None, _fontsize=30, _figsize=(30,15)): \n",
    "    \n",
    "    \"\"\"\n",
    "    Plots the confusion matrix for automatically determined threshold values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        _data: pandas-data-frame\n",
    "            It contains both manually assessed and automatically determined thresholds for each mouse identifier \n",
    "            and hearing stimulus. \n",
    "            \n",
    "        _column: string\n",
    "            The name of the column in which the automatically determined thresholds are stored.\n",
    "    \"\"\"\n",
    "    \n",
    "    predicted_thr = _column\n",
    "    result_columns = ['mouse_id', 'frequency', 'threshold'] + [_column]\n",
    "    \n",
    "    result_test2 = _data[result_columns].drop_duplicates()\n",
    "    \n",
    "    confusion_mtx = confusion_matrix(result_test2['threshold'], result_test2[predicted_thr]) \n",
    "   \n",
    "    columns = [int(x) for x in sorted(result_test2[predicted_thr].unique())]\n",
    "    merged_list = list(itertools.chain(*itertools.zip_longest(result_test2['threshold'].unique(), \n",
    "                                                              result_test2[predicted_thr].unique())))\n",
    "    merged_list = [i for i in merged_list if i is not None]\n",
    "    merged_list = sorted(set(merged_list))\n",
    "    \n",
    "    confusion_mtx = pd.DataFrame(confusion_mtx, index = merged_list, \n",
    "                                 columns = merged_list)\n",
    "    for sl in range(0, 100, 5):\n",
    "        if sl not in confusion_mtx.index:\n",
    "            confusion_mtx[sl] = 0\n",
    "            confusion_mtx.loc[sl] = 0\n",
    "    confusion_mtx = confusion_mtx.sort_index(axis=1).sort_index()\n",
    "    \n",
    "    fig = plt.figure(figsize=_figsize)\n",
    "    fontsize = _fontsize\n",
    "    \n",
    "    ax = sns.heatmap(confusion_mtx, annot=True, fmt=\"d\", \n",
    "                     annot_kws={\"size\": fontsize-15}, cbar_kws={\"pad\": 0.02},\n",
    "                     square=True, center=250, vmin=0, vmax=1000, cmap='Spectral_r') \n",
    "    ax.xaxis.tick_top()\n",
    "    ax.xaxis.set_label_position('top') \n",
    "    label = 'NN predicted threshold' if 'nn' in _column else 'SLR estimated threshold'\n",
    "    \n",
    "    ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize=fontsize-10)\n",
    "    ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize=fontsize-10)\n",
    "    \n",
    "    ax.set_xlabel(label, fontsize=fontsize, labelpad=15)\n",
    "    ax.set_ylabel('Manual threshold', fontsize=fontsize, labelpad=15)\n",
    "    \n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.set_yticklabels(cbar.ax.get_ymajorticklabels(), fontsize=fontsize-10)  \n",
    "    \n",
    "    if _title:\n",
    "        ax.set_title(_title, fontsize=fontsize+5, pad=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T06:55:34.483045Z",
     "start_time": "2021-05-03T06:55:34.423065Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_stimulus_specific(_data, _column, _title=None, _fontsize=30, _figsize=(30,45)): \n",
    "    \n",
    "    \"\"\"\n",
    "    Plots the confusion matrix for automatically determined thresholds for each stimulus separately.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        _data: pandas-data-frame\n",
    "            It contains both manually assessed and automatically determined thresholds for each mouse identifier \n",
    "            and hearing stimulus. \n",
    "            \n",
    "        _column: string\n",
    "            The name of the column in which the automatically determined thresholds are stored.\n",
    "    \"\"\"\n",
    "    \n",
    "    predicted_thr = _column\n",
    "    result_columns = ['mouse_id', 'frequency', 'threshold'] + [_column]\n",
    "    \n",
    "    rows = 3\n",
    "    cols = 2\n",
    "    \n",
    "    row = 0\n",
    "    col = 0\n",
    "    \n",
    "    fig, axes = plt.subplots(ncols=cols, nrows=rows, #gridspec_kw={'wspace': 5},\n",
    "                             sharey=False, sharex=False, figsize=_figsize, constrained_layout=True)\n",
    "    fontsize = _fontsize\n",
    "    \n",
    "    for freq in _data.frequency.unique():\n",
    "        \n",
    "        result_test2 = _data[_data.frequency == freq][result_columns].drop_duplicates()\n",
    "    \n",
    "        confusion_mtx = confusion_matrix(result_test2['threshold'], result_test2[predicted_thr]) \n",
    "        index = [int(x) for x in sorted(result_test2['threshold'].unique())]\n",
    "   \n",
    "        columns = [int(x) for x in sorted(result_test2[predicted_thr].unique())]\n",
    "        merged_list = list(itertools.chain(*itertools.zip_longest(result_test2['threshold'].unique(), \n",
    "                                                              result_test2[predicted_thr].unique())))\n",
    "        merged_list = [i for i in merged_list if i is not None]\n",
    "        merged_list = sorted(set(merged_list))\n",
    "    \n",
    "        confusion_mtx = pd.DataFrame(confusion_mtx, index = merged_list, \n",
    "                                     columns = merged_list)\n",
    "        for sl in range(0, 100, 5):\n",
    "            if sl not in confusion_mtx.index:\n",
    "                confusion_mtx[sl] = 0\n",
    "                confusion_mtx.loc[sl] = 0\n",
    "        confusion_mtx = confusion_mtx.sort_index(axis=1).sort_index()\n",
    "        \n",
    "        sns.heatmap(confusion_mtx, annot=True, fmt=\"d\", \n",
    "                    annot_kws={\"size\": fontsize-15}, cbar_kws={\"pad\": 0.02, 'shrink': 0.9},\n",
    "                    square=True, center=250, vmin=0, vmax=300, cmap='Spectral_r', ax=axes[row,col]) \n",
    "        axes[row,col].xaxis.tick_top()\n",
    "        axes[row,col].xaxis.set_label_position('top') \n",
    "        \n",
    "        axes[row,col].set_xticklabels(axes[row,col].get_xmajorticklabels(), fontsize=fontsize-10)\n",
    "        axes[row,col].set_yticklabels(axes[row,col].get_ymajorticklabels(), fontsize=fontsize-10)\n",
    "        \n",
    "        label = 'NN predicted threshold' if 'nn' in _column else 'SLR estimated threshold'\n",
    "        axes[row,col].set_xlabel(label, fontsize=fontsize, labelpad=15)\n",
    "        if col == 0:\n",
    "            axes[row,col].set_ylabel('Manual threshold', fontsize=fontsize, labelpad=15)\n",
    "        if freq == 100:\n",
    "            axes[row,col].set_title('Click', fontsize=fontsize, pad=15)\n",
    "        else:\n",
    "            axes[row,col].set_title('%d kHz' % (freq/1000), fontsize=fontsize, pad=15)\n",
    "            \n",
    "        cbar = axes[row,col].collections[0].colorbar\n",
    "        cbar.ax.set_yticklabels(cbar.ax.get_ymajorticklabels(), fontsize=fontsize-10)  \n",
    "        \n",
    "        col += 1\n",
    "        if col == cols:\n",
    "            row += 1\n",
    "            col = 0\n",
    "    \n",
    "    if _title:\n",
    "        fig.suptitle(_title, fontsize=_fontsize)\n",
    "    else:\n",
    "        fig.suptitle('NN models' if 'nn' in _column else 'SLR method', fontsize=_fontsize-10)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T06:55:35.622502Z",
     "start_time": "2021-05-03T06:55:35.548756Z"
    },
    "code_folding": [
     0,
     3,
     6,
     9
    ]
   },
   "outputs": [],
   "source": [
    "def double_std(array):\n",
    "    return np.std(array) * 2\n",
    "\n",
    "def q1(x):\n",
    "    return x.quantile(0.25)\n",
    "\n",
    "def q3(x):\n",
    "    return x.quantile(0.75)\n",
    "\n",
    "def plot_threshold_stats(_data, _columns=['threshold', 'nn_predicted_thr'], \n",
    "                         _stat='mean', _fontsize=20):\n",
    "    \n",
    "    # map 999 to 100\n",
    "    df = _data.copy()\n",
    "    for col in _columns:\n",
    "        df[col] = [100 if df.loc[idx, col] == 999 else df.loc[idx, col] for idx in df.index]\n",
    "    \n",
    "    df1 = df[['frequency', _columns[0]]].copy()   \n",
    "    df2 = df[['frequency', _columns[1]]].copy()\n",
    "    \n",
    "    if 'nn' in _columns[1]:\n",
    "        colors = ['green', 'mediumblue']\n",
    "    else:\n",
    "        colors = ['red', 'mediumblue']\n",
    "        \n",
    "    df1['threshold_type']=['Click: manual' if df1.at[idx, 'frequency']==100 else '%dkHz: manual' % (df1.at[idx, 'frequency']/1000) for idx in df1.index]\n",
    "    df2.rename(columns={_columns[1]: 'threshold'}, inplace=True)\n",
    "    if 'nn' in _columns[1]:\n",
    "        df2['threshold_type']=['Click: nn predicted' if df2.at[idx, 'frequency']==100 else '%dkHz: nn predicted' % (df2.at[idx, 'frequency']/1000) for idx in df2.index]\n",
    "    else:\n",
    "        df2['threshold_type']=['Click: slr estimated' if df2.at[idx, 'frequency']==100 else '%dkHz: slr estimated' % (df2.at[idx, 'frequency']/1000) for idx in df2.index]\n",
    "        \n",
    "    df = df1.append(df2).reset_index(drop=True) \n",
    "    df = df[df.columns.drop('frequency')]\n",
    "    thresholds = df.groupby(['threshold_type']).agg(\n",
    "        [np.mean, np.std, double_std, sp.sem, np.median, q1, q3])\n",
    "        \n",
    "    if 'nn' in _columns[1]:\n",
    "        row_type = 'nn predicted'\n",
    "    else:\n",
    "        row_type = 'slr estimated'\n",
    "    order = 0\n",
    "    for freq in sorted(_data.frequency.unique(), reverse=True):\n",
    "        if freq > 100:\n",
    "            thresholds.at['%dkHz: %s' % ((freq/1000), row_type), 'order'] = order\n",
    "            order+=1\n",
    "            thresholds.at['%dkHz: manual' % (freq/1000), 'order'] = order\n",
    "            order+=1             \n",
    "    thresholds.at['Click: %s' % row_type, 'order'] = order\n",
    "    order+=1\n",
    "    thresholds.at['Click: manual', 'order'] = order\n",
    "    thresholds.sort_values(by='order', inplace=True)        \n",
    "        \n",
    "    xerr = 'std'\n",
    "    _title = 'Threshold Mean'\n",
    "    if _stat == 'median':\n",
    "        xerr = None\n",
    "        _title = 'Threshold Median'\n",
    "        \n",
    "    ax = thresholds['threshold'].plot(kind='barh', y=_stat, legend=False, grid=True, zorder=3,\n",
    "                                      color=colors, xerr=xerr, capsize=4, \n",
    "                                      fontsize=_fontsize)\n",
    "    ax.grid(zorder=0, color='lightgray')\n",
    "    ax.set_title(_title, pad=15)\n",
    "    ax.title.set_size(_fontsize+5)\n",
    "        \n",
    "    if _stat == 'median':\n",
    "        for idx, thr_type in enumerate(thresholds['threshold'].index): \n",
    "                \n",
    "            plt.hlines(y=thr_type, \n",
    "                       xmin=thresholds['threshold'].at[thr_type, 'q1'], xmax=thresholds['threshold'].at[thr_type, 'q3'], \n",
    "                       colors='black', linewidths=1.5)\n",
    "            plt.vlines(x=thresholds['threshold'].at[thr_type, 'q1'], ymin=idx-0.12, ymax=idx+0.12, colors='black', linewidths=1)\n",
    "            plt.vlines(x=thresholds['threshold'].at[thr_type, 'q3'], ymin=idx-0.12, ymax=idx+0.12, colors='black', linewidths=1)\n",
    "        \n",
    "    ax.set_xlabel('dB', fontsize=_fontsize)\n",
    "    ax.set_ylabel('')\n",
    "        \n",
    "    for key, spine in ax.spines.items():\n",
    "        spine.set_visible(False)\n",
    "    ax.tick_params(bottom=False, left=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T06:55:38.391515Z",
     "start_time": "2021-05-03T06:55:38.327202Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_threshold_boxplots(_data, _columns=['threshold', 'nn_predicted_thr'], \n",
    "                            _figsize=(15, 10), _fontsize=20):\n",
    "    \n",
    "    # map 999 to 100\n",
    "    df = _data.copy()\n",
    "    for col in _columns:\n",
    "        df[col] = [100 if df.loc[idx, col] == 999 else df.loc[idx, col] for idx in df.index]\n",
    "    \n",
    "    df1 = df[['frequency', _columns[0]]].copy()   \n",
    "    df2 = df[['frequency', _columns[1]]].copy()\n",
    "    \n",
    "    df1['threshold type']=['Click: manual' if df1.at[idx, 'frequency']==100 else '%dkHz: manual' % (df1.at[idx, 'frequency']/1000) for idx in df1.index]\n",
    "    df2.rename(columns={_columns[1]: 'threshold'}, inplace=True)\n",
    "    if 'nn' in _columns[1]:\n",
    "        df2['threshold type']=['Click: nn predicted' if df2.at[idx, 'frequency']==100 else '%dkHz: nn predicted' % (df2.at[idx, 'frequency']/1000) for idx in df2.index]\n",
    "    else:\n",
    "        df2['threshold type']=['Click: slr estimated' if df2.at[idx, 'frequency']==100 else '%dkHz: slr estimated' % (df2.at[idx, 'frequency']/1000) for idx in df2.index]\n",
    "        \n",
    "    df = pd.concat([df1, df2]).reset_index(drop=True)\n",
    "    df.rename(columns={'threshold': 'threshold (dB)'}, inplace=True)\n",
    "    \n",
    "    if 'nn' in _columns[1]:\n",
    "        colors = ['mediumblue', 'green']\n",
    "    else:\n",
    "        colors = ['mediumblue', 'red']\n",
    "        \n",
    "    if 'nn' in _columns[1]:\n",
    "        row_type = 'nn predicted'\n",
    "    else:\n",
    "        row_type = 'slr estimated'\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=_figsize)\n",
    "    ax.set_ylabel('dB', fontsize=_fontsize, labelpad=15)\n",
    "    \n",
    "    # Remove top and right border\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    \n",
    "    # Remove y-axis tick marks\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    \n",
    "    # Add major gridlines\n",
    "    ax.grid(zorder=0, color='lightgray', linestyle='-')#, linewidth=0.25, alpha=0.5)\n",
    "    ax.title.set_size(_fontsize+5)\n",
    "    \n",
    "    # Set threshold types as labels for the boxplot\n",
    "    labels = ['Click: manual', 'Click: %s' % row_type]\n",
    "    for freq in sorted(df.frequency.unique()):\n",
    "        if freq > 100:\n",
    "            labels.append('%dkHz: manual' % (freq/1000))\n",
    "            labels.append('%dkHz: %s' % ((freq/1000), row_type))\n",
    "            \n",
    "    dataset = [df[df['threshold type'] == thr_type]['threshold (dB)'] for thr_type in labels]\n",
    "\n",
    "    \"\"\"\n",
    "    We want to apply different properties to each threshold type, so we're going to plot one boxplot\n",
    "    for each threshold type and set their properties individually\n",
    "        positions: position of the boxplot in the plot area\n",
    "        medianprops: dictionary of properties applied to median line\n",
    "        whiskerprops: dictionary of properties applied to the whiskers\n",
    "        capprops: dictionary of properties applied to the caps on the whiskers\n",
    "        flierprops: dictionary of properties applied to outliers\n",
    "    \"\"\"\n",
    "    \n",
    "    medianprops = dict(linestyle='-', linewidth=3, color='k')\n",
    "    \n",
    "    for idx,ds in enumerate(dataset):\n",
    "        ax.boxplot(ds, zorder=3,  \n",
    "                   positions=[idx+1], labels=[labels[idx]], \n",
    "                   boxprops=dict(color=colors[idx%2], linewidth=3), \n",
    "                   medianprops=medianprops, \n",
    "                   whiskerprops=dict(color=colors[idx%2]), \n",
    "                   capprops=dict(color=colors[idx%2]), \n",
    "                   flierprops=dict(markeredgecolor=colors[idx%2]))\n",
    "    \n",
    "    plt.xticks(fontsize=_fontsize, rotation = 90)\n",
    "    plt.yticks(fontsize=_fontsize)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T09:12:20.236797Z",
     "start_time": "2021-05-07T09:12:20.173541Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_evaluation_curves(_dataset, _xlabel, _ylabel, _fontsize=30, _figsize=(20, 13)):\n",
    "    \n",
    "    # name columns containing the ABR wave time series data\n",
    "    timeseries_columns = ['t%d' %i for i in range(1000)] \n",
    "    \n",
    "    thresholds = ['threshold manual', 'threshold SLR', 'threshold NN', 50]\n",
    "    fig = plt.figure(constrained_layout=True, figsize=_figsize)\n",
    "    \n",
    "    ncols = 3\n",
    "    nrows = int(len(_dataset.frequency.unique())/ncols)\n",
    "    col = 0\n",
    "    row = 0\n",
    "    spec = gridspec.GridSpec(ncols=ncols, nrows=nrows, figure=fig)\n",
    "    ax = {}\n",
    "    \n",
    "    legend_elements = []\n",
    "    for idx, freq in enumerate(sorted(_dataset.frequency.unique())):\n",
    "        if idx == 0:\n",
    "            ax[idx] = fig.add_subplot(spec[row, col])\n",
    "        else:\n",
    "            ax[idx] = fig.add_subplot(spec[row, col], sharex=ax[idx-1], sharey=ax[idx-1])\n",
    "        if freq == 100:\n",
    "            ax[idx].set_title('Click', fontsize=_fontsize, y=1.01)#, fontweight='bold'\n",
    "        else:\n",
    "            ax[idx].set_title('%dkHz' % int(float(freq)/1000), fontsize=_fontsize, y=1.01)#, fontweight='bold'\n",
    "    \n",
    "        ax[idx].set_xticks([0.25,0.5,0.75,1.0])\n",
    "        ax[idx].tick_params(axis='x', labelsize=_fontsize-5)\n",
    "        ax[idx].tick_params(axis='y', labelsize=_fontsize-5)\n",
    "        # ax[idx].grid(color='lightgray')\n",
    "    \n",
    "        if col == 0:\n",
    "            if row == nrows-1:\n",
    "                legend_elements = plot_evaluation_curve_for_specific_stimulus(_dataset, freq, thresholds,\n",
    "                                                                              timeseries_columns,\n",
    "                                                                              frequency = 'frequency',\n",
    "                                                                              sound_level = 'sound_level', \n",
    "                                                                              fontsize=_fontsize,\n",
    "                                                                              legend=False,\n",
    "                                                                              xlabel=_xlabel,\n",
    "                                                                              ylabel=_ylabel,\n",
    "                                                                              ax=ax[idx])\n",
    "            else:\n",
    "                legend_elements = plot_evaluation_curve_for_specific_stimulus(_dataset, freq, thresholds,\n",
    "                                                                              timeseries_columns,\n",
    "                                                                              frequency = 'frequency',\n",
    "                                                                              sound_level = 'sound_level', \n",
    "                                                                              fontsize=_fontsize,\n",
    "                                                                              legend=False, \n",
    "                                                                              xlabel=None,\n",
    "                                                                              ylabel=_ylabel,\n",
    "                                                                              ax=ax[idx])\n",
    "        else:\n",
    "            if row==nrows-1:\n",
    "                legend_elements = plot_evaluation_curve_for_specific_stimulus(_dataset, freq, thresholds,\n",
    "                                                                              timeseries_columns,\n",
    "                                                                              frequency = 'frequency',\n",
    "                                                                              sound_level = 'sound_level', \n",
    "                                                                              fontsize=_fontsize,\n",
    "                                                                              legend=False,\n",
    "                                                                              xlabel=_xlabel,\n",
    "                                                                              ylabel=None,\n",
    "                                                                              ax=ax[idx])\n",
    "            else:\n",
    "                legend_elements = plot_evaluation_curve_for_specific_stimulus(_dataset, freq, thresholds,\n",
    "                                                                              timeseries_columns,\n",
    "                                                                              frequency = 'frequency',\n",
    "                                                                              sound_level = 'sound_level', \n",
    "                                                                              fontsize=_fontsize,\n",
    "                                                                              legend=False, \n",
    "                                                                              xlabel=None,\n",
    "                                                                              ylabel=None,\n",
    "                                                                              ax=ax[idx])\n",
    "    \n",
    "        col+=1\n",
    "        if col == ncols:\n",
    "            row+=1\n",
    "            col=0\n",
    "            \n",
    "    leg = fig.legend(handles=legend_elements, loc='lower left', bbox_to_anchor= (0.061, 1.01), ncol=2, \n",
    "                     borderaxespad=0, frameon=True, fontsize=_fontsize, title_fontsize=_fontsize-5)\n",
    "    leg._legend_box.align = \"left\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load GMC data\n",
    "\n",
    "Load the ABR curves from the German Mouse Clinic and the lists of mice used to train, validate and test the NN/SLR models.</br>\n",
    "The files can be found under the path specified by _path2data_:\n",
    "\n",
    "* _GMC/GMC_abr_curves.csv_\n",
    "* _GMC/GMC_train_mice.npy_\n",
    "* _GMC/GMC_valid_mice.npy_\n",
    "* _GMC/GMC_test_mice.npy_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Load the manually assessed thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T09:18:49.987914Z",
     "start_time": "2021-05-07T09:13:33.415440Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Load the ABR curves from GMC\"\"\"\n",
    "GMC_data = pd.read_csv(os.path.join(path2data, 'GMC', 'GMC_abr_curves.csv'), low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T08:56:53.612243Z",
     "start_time": "2021-04-28T08:56:53.596725Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Load training, validation and test mouse ids\"\"\"\n",
    "GMC_mice = {}\n",
    "for _ in ['train', 'valid', 'test']:\n",
    "    GMC_mice[_] = np.load(os.path.join(path2data, 'GMC', 'GMC_'+_+'_mice.npy'))\n",
    "    print('GMC %s mice: %d' % (_, len(GMC_mice[_])))\n",
    "    \n",
    "GMC_data['mouse_group'] = ['train' if mouse_id in GMC_mice['train'] else 'valid' if mouse_id in GMC_mice['valid'] else 'test' for mouse_id in GMC_data['mouse_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Load the NN predicted thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T08:51:59.951601Z",
     "start_time": "2021-05-07T08:51:59.787506Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Load predictions by neural networks trained with GMC data (GMCtrained_NN)\"\"\"\n",
    "GMC_data_predictions1 = pd.read_csv(os.path.join(path2results, 'GMC_data_GMCtrained_NN_predictions.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T08:52:01.555776Z",
     "start_time": "2021-05-07T08:52:01.401732Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Load predictions by neural networks trained with Ingham et al. data (INGtrained_NN)\"\"\"\n",
    "GMC_data_predictions2 = pd.read_csv(os.path.join(path2results, 'GMC_data_INGtrained_NN_predictions.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Load the SLR estimated thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T08:52:03.753344Z",
     "start_time": "2021-05-07T08:52:03.686345Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Load estimations made by SLR calibrated with GMC training data (GMCcalibrated_SLR)\"\"\"\n",
    "GMC_data_estimations1 = pd.read_csv(os.path.join(path2results, 'GMC_data_GMCcalibrated_SLR_estimations.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T08:52:05.727887Z",
     "start_time": "2021-05-07T08:52:05.663314Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Load estimations made by SLR calibrated with ING training data (INGcalibrated_SLR)\"\"\"\n",
    "GMC_data_estimations2 = pd.read_csv(os.path.join(path2results, 'GMC_data_INGcalibrated_SLR_estimations.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load ING data\n",
    "\n",
    "Load the ABR curves provided by Ingham et al. and the lists of mice used to train, validate and test the NN/SLR models.</br>\n",
    "The files can be found under the path specified by _path2data_:\n",
    "* _ING/ING_abr_curves.csv_\n",
    "* _ING/ING_train_mice.npy_\n",
    "* _ING/ING_valid_mice.npy_\n",
    "* _ING/ING_test_mice.npy_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T09:32:29.411474Z",
     "start_time": "2021-05-07T09:22:07.958881Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Load the ING ABR curves\"\"\"\n",
    "ING_data = pd.read_csv(os.path.join(path2data, 'ING', 'ING_abr_curves.csv'), low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T09:12:26.412857Z",
     "start_time": "2021-04-28T09:12:26.387821Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Load training, validation and test mouse IDs\"\"\"\n",
    "\n",
    "# call load_data with allow_pickle set to true\n",
    "ING_mice = {}\n",
    "for _ in ['train', 'valid', 'test']:\n",
    "    ING_mice[_] = np.load(os.path.join(path2data, 'ING', 'ING_'+_+'_mice.npy'), allow_pickle=True)\n",
    "    print('ING %s mice: %d' % (_, len(ING_mice[_])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Load NN predicted thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T08:52:24.119459Z",
     "start_time": "2021-05-07T08:52:23.864351Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Load predictions by neural networks trained with GMC data (GMCtrained_NN)\"\"\"\n",
    "ING_data_predictions1 = pd.read_csv(os.path.join(path2results, 'ING_data_GMCtrained_NN_predictions.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T08:52:25.180788Z",
     "start_time": "2021-05-07T08:52:24.957830Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Load predictions by neural networks trained with ING data (INGtrained_NN)\"\"\"\n",
    "ING_data_predictions2 = pd.read_csv(os.path.join(path2results, 'ING_data_INGtrained_NN_predictions.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Load SLR estimated thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T08:52:29.243741Z",
     "start_time": "2021-05-07T08:52:29.164625Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Load estimations by SLR calibrated with GMC training data (GMCcalibrated_SLR)\"\"\"\n",
    "ING_data_estimations1 = pd.read_csv(os.path.join(path2results, 'ING_data_GMCcalibrated_SLR_estimations.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T08:52:32.799287Z",
     "start_time": "2021-05-07T08:52:32.722105Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Load estimations by SLR calibrated with ING training data (INGcalibrated_SLR)\"\"\"\n",
    "ING_data_estimations2 = pd.read_csv(os.path.join(path2results, 'ING_data_INGcalibrated_SLR_estimations.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation approaches \n",
    "\n",
    "+ threshold detection accuracy\n",
    "+ standardised error plots - threshold detection absolute error standardised to the hearing threshold variance\n",
    "+ relationship between manually and ML-detected thresholds using the median as aggregation method\n",
    "+ confusion matrix plots\n",
    "+ stimulus specific threshold averages\n",
    "+ stimulus specific threshold medians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "\n",
    "NNs trained with the GMC training data set and tested on the GMC test data set:\n",
    "* NN GMC-GMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T09:16:21.818778Z",
     "start_time": "2021-04-28T09:16:21.808371Z"
    }
   },
   "outputs": [],
   "source": [
    "GMC_test_data_predictions1 = GMC_data_predictions1[GMC_data_predictions1.mouse_id.isin(GMC_mice['test'])]\n",
    "title = 'GMC trained NNs / GMC test data set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T09:29:09.477142Z",
     "start_time": "2021-04-28T09:29:09.393463Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Print overall mouse metrics\"\"\"\n",
    "abrthr.print_overall_mouse_metrics(\n",
    "    GMC_test_data_predictions1, _predicted_thr_col='nn_predicted_thr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T09:33:55.063731Z",
     "start_time": "2021-04-28T09:33:53.410066Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the threshold error normalised to the variance, overall and stimulus specific\"\"\"\n",
    "\n",
    "xlabel = 'Threshold error normalised to the variance'\n",
    "ylabel = 'Threshold assessments in percent'\n",
    "\n",
    "plot_standardised_error(GMC_test_data_predictions1, \n",
    "                        'threshold', 'nn_predicted_thr', \n",
    "                        _title='', _xlabel=xlabel, _ylabel=ylabel)\n",
    "plot_standardised_error(GMC_test_data_predictions1, \n",
    "                       'threshold', 'nn_predicted_thr', \n",
    "                        _title='', _xlabel=xlabel, _ylabel=ylabel,\n",
    "                        _freq_specific=True, \n",
    "                        _figsize=(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(df[df.threshold==15]['nn_predicted_thr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T18:17:26.474119Z",
     "start_time": "2021-04-28T18:17:24.626154Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the medians of the NN predicted thresholds against the manually assessed thresholds, overall and stimulus specific\"\"\"\n",
    "\n",
    "# map 999 to 100\n",
    "df = GMC_test_data_predictions1.copy()\n",
    "for col in ['threshold', 'nn_predicted_thr']:\n",
    "    df[col] = [100 if df.loc[idx, col] == 999 else df.loc[idx, col] for idx in df.index]\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    plot_median(df, 'nn_predicted_thr', _figsize=(21,20))\n",
    "    plot_median_stimulus_specific(df, 'nn_predicted_thr', _figsize=(30,45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T13:27:31.094855Z",
     "start_time": "2021-04-28T13:27:08.018885Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the confusion matrix, overall and stimulus specific\"\"\"\n",
    "\n",
    "plot_confusion_matrix(GMC_test_data_predictions1, 'nn_predicted_thr')\n",
    "plot_confusion_matrix_stimulus_specific(GMC_test_data_predictions1, 'nn_predicted_thr', _figsize=(30,45), _title=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T14:15:31.626752Z",
     "start_time": "2021-04-28T14:15:30.224526Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Stimulus specific plots of the threshold mean as horizontal bars\"\"\"\n",
    "plot_threshold_stats(GMC_test_data_predictions1)\n",
    "\n",
    "\"\"\"Stimulus specific plots of the threshold median as horizontal bars\"\"\"\n",
    "plot_threshold_stats(GMC_test_data_predictions1, _stat='median')\n",
    "\n",
    "\"\"\"Plot of threshold value boxplots grouped by threshold type\"\"\"\n",
    "plot_threshold_boxplots(GMC_test_data_predictions1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Experiment 2\n",
    "\n",
    "NNs trained with the GMC training data set and tested on ING data:\n",
    "* NN GMC-ING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T14:18:04.383943Z",
     "start_time": "2021-04-28T14:18:04.378853Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "title = 'GMC trained NNs / ING data set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T14:19:04.588251Z",
     "start_time": "2021-04-28T14:19:04.456845Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Print overall mouse metrics\"\"\"\n",
    "abrthr.print_overall_mouse_metrics(ING_data_predictions1, \n",
    "                                  _predicted_thr_col='nn_predicted_thr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T14:25:38.620844Z",
     "start_time": "2021-04-28T14:25:32.501967Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the threshold error normalised to the variance, overall and stimulus specific\"\"\"\n",
    "\n",
    "xlabel = 'Threshold error normalised to the variance'\n",
    "ylabel = 'Threshold assessments in percent'\n",
    "\n",
    "plot_standardised_error(ING_data_predictions1, \n",
    "                        'threshold', 'nn_predicted_thr', \n",
    "                        _title='', _xlabel=xlabel, _ylabel=ylabel)\n",
    "plot_standardised_error(ING_data_predictions1, \n",
    "                        'threshold', 'nn_predicted_thr', \n",
    "                        _title='', _xlabel=xlabel, _ylabel=ylabel, \n",
    "                        _freq_specific=True, \n",
    "                        _figsize=(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T18:17:05.463421Z",
     "start_time": "2021-04-28T18:17:01.820677Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the medians of the NN predicted thresholds against the manually assessed thresholds, overall and stimulus specific\"\"\"\n",
    "\n",
    "# map 999 to 100\n",
    "df = ING_data_predictions1.copy()\n",
    "for col in ['threshold', 'nn_predicted_thr']:\n",
    "    df[col] = [100 if df.loc[idx, col] == 999 else df.loc[idx, col] for idx in df.index]\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    plot_median(df, 'nn_predicted_thr', _figsize=(21,20))\n",
    "    plot_median_stimulus_specific(df, 'nn_predicted_thr', _figsize=(30,45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T14:30:10.164861Z",
     "start_time": "2021-04-28T14:29:34.375879Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the confusion matrix, overall and stimulus specific\"\"\"\n",
    "\n",
    "plot_confusion_matrix(ING_data_predictions1, 'nn_predicted_thr')\n",
    "plot_confusion_matrix_stimulus_specific(ING_data_predictions1, 'nn_predicted_thr', _figsize=(30,45), _title=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T14:31:02.959332Z",
     "start_time": "2021-04-28T14:30:55.005295Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Stimulus specific plots of the threshold mean as horizontal bars\"\"\"\n",
    "plot_threshold_stats(ING_data_predictions1)\n",
    "\n",
    "\"\"\"Stimulus specific plots of the threshold median as horizontal bars\"\"\"\n",
    "plot_threshold_stats(ING_data_predictions1, _stat='median')\n",
    "\n",
    "\"\"\"Plot of threshold value boxplots grouped by threshold type\"\"\"\n",
    "plot_threshold_boxplots(ING_data_predictions1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Experiment 3\n",
    "\n",
    "NNs trained with the ING training data set and tested on GMC data:\n",
    "* NN ING-GMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T14:34:06.129680Z",
     "start_time": "2021-04-28T14:34:06.124903Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "title = 'ING trained NNs / GMC data set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T14:34:55.790116Z",
     "start_time": "2021-04-28T14:34:55.679946Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Print overall mouse metrics\"\"\"\n",
    "abrthr.print_overall_mouse_metrics(GMC_data_predictions2, \n",
    "                                  _predicted_thr_col='nn_predicted_thr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T14:36:14.858527Z",
     "start_time": "2021-04-28T14:36:11.160667Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the threshold error normalised to the variance, overall and stimulus specific\"\"\"\n",
    "\n",
    "xlabel = 'Threshold error normalised to the variance'\n",
    "ylabel = 'Threshold assessments in percent'\n",
    "\n",
    "plot_standardised_error(GMC_data_predictions2, \n",
    "                        'threshold', 'nn_predicted_thr', \n",
    "                        _title='', _xlabel=xlabel, _ylabel=ylabel)\n",
    "plot_standardised_error(GMC_data_predictions2, \n",
    "                        'threshold', 'nn_predicted_thr', \n",
    "                        _title='', _xlabel=xlabel, _ylabel=ylabel, \n",
    "                        _freq_specific=True, \n",
    "                        _figsize=(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T18:16:44.451228Z",
     "start_time": "2021-04-28T18:16:41.815617Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the medians of the NN predicted thresholds against the manually assessed thresholds, overall and stimulus specific\"\"\"\n",
    "\n",
    "# map 999 to 100\n",
    "df = GMC_data_predictions2.copy()\n",
    "for col in ['threshold', 'nn_predicted_thr']:\n",
    "    df[col] = [100 if df.loc[idx, col] == 999 else df.loc[idx, col] for idx in df.index]\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    plot_median(df, 'nn_predicted_thr', _figsize=(21,20))\n",
    "    plot_median_stimulus_specific(df, 'nn_predicted_thr', _figsize=(30,45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T14:39:47.090467Z",
     "start_time": "2021-04-28T14:39:13.833667Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the confusion matrix, overall and stimulus specific\"\"\"\n",
    "\n",
    "plot_confusion_matrix(GMC_data_predictions2, 'nn_predicted_thr')\n",
    "plot_confusion_matrix_stimulus_specific(GMC_data_predictions2, 'nn_predicted_thr', _figsize=(30,45), _title=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T14:42:10.770043Z",
     "start_time": "2021-04-28T14:42:06.818218Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Stimulus specific plots of the threshold mean as horizontal bars\"\"\"\n",
    "plot_threshold_stats(GMC_data_predictions2)\n",
    "\n",
    "\"\"\"Stimulus specific plots of the threshold median as horizontal bars\"\"\"\n",
    "plot_threshold_stats(GMC_data_predictions2, _stat='median')\n",
    "\n",
    "\"\"\"Plot of threshold value boxplots grouped by threshold type\"\"\"\n",
    "plot_threshold_boxplots(GMC_data_predictions2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Experiment 4\n",
    "\n",
    "NNs trained with the ING training data set and tested on the ING test data set:\n",
    "* NN ING-ING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T14:48:22.147202Z",
     "start_time": "2021-04-28T14:48:22.126610Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ING_test_data_predictions2 = ING_data_predictions2[ING_data_predictions2.mouse_id.isin(ING_mice['test'])]\n",
    "title = 'ING trained NNs / ING test data set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T14:48:23.113384Z",
     "start_time": "2021-04-28T14:48:23.033920Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Print overall mouse metrics\"\"\"\n",
    "abrthr.print_overall_mouse_metrics(ING_test_data_predictions2, \n",
    "                                  _predicted_thr_col='nn_predicted_thr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T14:49:14.519935Z",
     "start_time": "2021-04-28T14:49:12.593988Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the threshold error normalised to the variance, overall and stimulus specific\"\"\"\n",
    "\n",
    "xlabel = 'Threshold error normalised to the variance'\n",
    "ylabel = 'Threshold assessments in percent'\n",
    "\n",
    "plot_standardised_error(ING_test_data_predictions2, \n",
    "                        'threshold', 'nn_predicted_thr', \n",
    "                        _title='', _xlabel=xlabel, _ylabel=ylabel)\n",
    "plot_standardised_error(ING_test_data_predictions2, \n",
    "                        'threshold', 'nn_predicted_thr', \n",
    "                        _title='', _xlabel=xlabel, _ylabel=ylabel, \n",
    "                        _freq_specific=True, \n",
    "                        _figsize=(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T18:16:23.354224Z",
     "start_time": "2021-04-28T18:16:21.151569Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the medians of the NN predicted thresholds against the manually assessed thresholds, overall and stimulus specific\"\"\"\n",
    "\n",
    "# map 999 to 100\n",
    "df = ING_test_data_predictions2.copy()\n",
    "for col in ['threshold', 'nn_predicted_thr']:\n",
    "    df[col] = [100 if df.loc[idx, col] == 999 else df.loc[idx, col] for idx in df.index]\n",
    "    \n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    plot_median(df, 'nn_predicted_thr', _figsize=(21,20))\n",
    "    plot_median_stimulus_specific(df, 'nn_predicted_thr', _figsize=(30,45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T14:52:23.870546Z",
     "start_time": "2021-04-28T14:51:47.424076Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the confusion matrix, overall and stimulus specific\"\"\"\n",
    "\n",
    "plot_confusion_matrix(ING_test_data_predictions2, 'nn_predicted_thr')\n",
    "plot_confusion_matrix_stimulus_specific(ING_test_data_predictions2, 'nn_predicted_thr', _figsize=(30,45), _title=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T15:02:50.951097Z",
     "start_time": "2021-04-28T15:02:49.129504Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Stimulus specific plots of the threshold mean as horizontal bars\"\"\"\n",
    "plot_threshold_stats(ING_test_data_predictions2)\n",
    "\n",
    "\"\"\"Stimulus specific plots of the threshold median as horizontal bars\"\"\"\n",
    "plot_threshold_stats(ING_test_data_predictions2, _stat='median')\n",
    "\n",
    "\"\"\"Plot of threshold value boxplots grouped by threshold type\"\"\"\n",
    "plot_threshold_boxplots(ING_test_data_predictions2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Experiment 5\n",
    "\n",
    "SLR method calibrated with the GMC training data set and tested on GMC data:\n",
    "* SLR GMC-GMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T15:29:23.685741Z",
     "start_time": "2021-04-28T15:29:23.680835Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "title = 'GMC calibrated SLR method / GMC data set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T15:30:02.530706Z",
     "start_time": "2021-04-28T15:30:02.430745Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Print overall mouse metrics\"\"\"\n",
    "abrthr.print_overall_mouse_metrics(GMC_data_estimations1, \n",
    "                                  _predicted_thr_col='slr_estimated_thr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T15:32:53.086562Z",
     "start_time": "2021-04-28T15:32:49.185037Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the threshold error normalised to the variance, overall and stimulus specific\"\"\"\n",
    "\n",
    "xlabel = 'Threshold error normalised to the variance'\n",
    "ylabel = 'Threshold assessments in percent'\n",
    "\n",
    "plot_standardised_error(GMC_data_estimations1, \n",
    "                        'threshold', 'slr_estimated_thr', \n",
    "                        _title='', _xlabel=xlabel, _ylabel=ylabel)\n",
    "plot_standardised_error(GMC_data_estimations1, \n",
    "                        'threshold', 'slr_estimated_thr', \n",
    "                        _title='', _xlabel=xlabel, _ylabel=ylabel, \n",
    "                        _freq_specific=True, \n",
    "                        _figsize=(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T18:12:34.374434Z",
     "start_time": "2021-04-28T18:12:31.734401Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the medians of the SLR estimated thresholds against the manually assessed thresholds, overall and stimulus specific\"\"\"\n",
    "\n",
    "# map 999 to 100\n",
    "df = GMC_data_estimations1.copy()\n",
    "for col in ['threshold', 'slr_estimated_thr']:\n",
    "    df[col] = [100 if df.loc[idx, col] == 999 else df.loc[idx, col] for idx in df.index]\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    plot_median(df, 'slr_estimated_thr', _figsize=(21,20))\n",
    "    plot_median_stimulus_specific(df, 'slr_estimated_thr', _figsize=(30,45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T15:35:49.605598Z",
     "start_time": "2021-04-28T15:35:19.595047Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the confusion matrix, overall and stimulus specific\"\"\"\n",
    "\n",
    "plot_confusion_matrix(GMC_data_estimations1, 'slr_estimated_thr')\n",
    "plot_confusion_matrix_stimulus_specific(GMC_data_estimations1, 'slr_estimated_thr', _figsize=(30,45), _title=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T15:36:55.055506Z",
     "start_time": "2021-04-28T15:36:50.543173Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Stimulus specific plots of the threshold mean as horizontal bars\"\"\"\n",
    "plot_threshold_stats(GMC_data_estimations1, _columns=['threshold', 'slr_estimated_thr'])\n",
    "\n",
    "\"\"\"Stimulus specific plots of the threshold median as horizontal bars\"\"\"\n",
    "plot_threshold_stats(GMC_data_estimations1, _stat='median', _columns=['threshold', 'slr_estimated_thr'])\n",
    "\n",
    "\"\"\"Plot of threshold value boxplots grouped by threshold type\"\"\"\n",
    "plot_threshold_boxplots(GMC_data_estimations1, _columns=['threshold', 'slr_estimated_thr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Experiment 6\n",
    "\n",
    "SLR method calibrated with the GMC training data set and tested on ING data:\n",
    "* SLR GMC-ING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T15:39:19.031991Z",
     "start_time": "2021-04-28T15:39:19.027971Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "title = 'GMC calibrated SLR method / ING data set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T18:08:05.422022Z",
     "start_time": "2021-04-28T18:08:05.328388Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Print overall mouse metrics\"\"\"\n",
    "abrthr.print_overall_mouse_metrics(ING_data_estimations1, \n",
    "                                  _predicted_thr_col='slr_estimated_thr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T18:09:13.253940Z",
     "start_time": "2021-04-28T18:09:07.725549Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the threshold error normalised to the variance, overall and stimulus specific\"\"\"\n",
    "\n",
    "xlabel = 'Threshold error normalised to the variance'\n",
    "ylabel = 'Threshold assessments in percent'\n",
    "\n",
    "plot_standardised_error(ING_data_estimations1, \n",
    "                        'threshold', 'slr_estimated_thr', \n",
    "                        _title='', _xlabel=xlabel, _ylabel=ylabel)\n",
    "plot_standardised_error(ING_data_estimations1, \n",
    "                        'threshold', 'slr_estimated_thr', \n",
    "                        _title='', _xlabel=xlabel, _ylabel=ylabel, \n",
    "                        _freq_specific=True, \n",
    "                        _figsize=(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T18:12:09.518770Z",
     "start_time": "2021-04-28T18:12:05.747590Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the medians of the SLR estimated thresholds against the manually assessed thresholds, overall and stimulus specific\"\"\"\n",
    "\n",
    "# map 999 to 100\n",
    "df = ING_data_estimations1.copy()\n",
    "for col in ['threshold', 'slr_estimated_thr']:\n",
    "    df[col] = [100 if df.loc[idx, col] == 999 else df.loc[idx, col] for idx in df.index]\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    plot_median(df, 'slr_estimated_thr', _figsize=(21,20))\n",
    "    plot_median_stimulus_specific(df, 'slr_estimated_thr', _figsize=(30,45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T18:13:42.292270Z",
     "start_time": "2021-04-28T18:13:09.033693Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the confusion matrix, overall and stimulus specific\"\"\"\n",
    "\n",
    "plot_confusion_matrix(ING_data_estimations1, 'slr_estimated_thr')\n",
    "plot_confusion_matrix_stimulus_specific(ING_data_estimations1, 'slr_estimated_thr', _figsize=(30,45), _title=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-28T18:14:09.448012Z",
     "start_time": "2021-04-28T18:14:02.531695Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Stimulus specific plots of the threshold mean as horizontal bars\"\"\"\n",
    "plot_threshold_stats(ING_data_estimations1, _columns=['threshold', 'slr_estimated_thr'])\n",
    "\n",
    "\"\"\"Stimulus specific plots of the threshold median as horizontal bars\"\"\"\n",
    "plot_threshold_stats(ING_data_estimations1, _stat='median', _columns=['threshold', 'slr_estimated_thr'])\n",
    "\n",
    "\"\"\"Plot of threshold value boxplots grouped by threshold type\"\"\"\n",
    "plot_threshold_boxplots(ING_data_estimations1, _columns=['threshold', 'slr_estimated_thr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Experiment 7 \n",
    "\n",
    "SLR method calibrated with the ING training data set and tested on GMC data:\n",
    "* SLR ING-GMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T07:51:51.576110Z",
     "start_time": "2021-05-03T07:51:51.522767Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "title = 'ING calibrated SLR method / GMC data set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:02:52.574044Z",
     "start_time": "2021-05-03T17:02:52.476119Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Print overall mouse metrics\"\"\"\n",
    "abrthr.print_overall_mouse_metrics(GMC_data_estimations2, \n",
    "                                  _predicted_thr_col='slr_estimated_thr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T08:43:29.177958Z",
     "start_time": "2021-05-03T08:43:25.872959Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the threshold error normalised to the variance, overall and stimulus specific\"\"\"\n",
    "\n",
    "xlabel = 'Threshold error normalised to the variance'\n",
    "ylabel = 'Threshold assessments in percent'\n",
    "\n",
    "plot_standardised_error(GMC_data_estimations2, \n",
    "                        'threshold', 'slr_estimated_thr', \n",
    "                        _title='', _xlabel=xlabel, _ylabel=ylabel)\n",
    "plot_standardised_error(GMC_data_estimations2, \n",
    "                        'threshold', 'slr_estimated_thr', \n",
    "                        _title='', _xlabel=xlabel, _ylabel=ylabel, \n",
    "                        _freq_specific=True, \n",
    "                        _figsize=(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T08:44:15.767792Z",
     "start_time": "2021-05-03T08:44:13.177015Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the medians of the SLR estimated thresholds against the manually assessed thresholds, overall and stimulus specific\"\"\"\n",
    "\n",
    "# map 999 to 100\n",
    "df = GMC_data_estimations2.copy()\n",
    "for col in ['threshold', 'slr_estimated_thr']:\n",
    "    df[col] = [100 if df.loc[idx, col] == 999 else df.loc[idx, col] for idx in df.index]\n",
    "    \n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    plot_median(df, 'slr_estimated_thr', _figsize=(21,20))\n",
    "    plot_median_stimulus_specific(df, 'slr_estimated_thr', _figsize=(30,45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T08:46:25.029656Z",
     "start_time": "2021-05-03T08:45:58.335030Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the confusion matrix overall and stimulus specific\"\"\"\n",
    "\n",
    "plot_confusion_matrix(GMC_data_estimations2, 'slr_estimated_thr')\n",
    "plot_confusion_matrix_stimulus_specific(GMC_data_estimations2, 'slr_estimated_thr', _figsize=(30,45), _title=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T08:47:52.770623Z",
     "start_time": "2021-05-03T08:47:48.595191Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Stimulus specific plots of the threshold mean as horizontal bars\"\"\"\n",
    "plot_threshold_stats(GMC_data_estimations2, _columns=['threshold', 'slr_estimated_thr'])\n",
    "\n",
    "\"\"\"Stimulus specific plots of the threshold median as horizontal bars\"\"\"\n",
    "plot_threshold_stats(GMC_data_estimations2, _stat='median', _columns=['threshold', 'slr_estimated_thr'])\n",
    "\n",
    "\"\"\"Plot of threshold value boxplots grouped by threshold type\"\"\"\n",
    "plot_threshold_boxplots(GMC_data_estimations2, _columns=['threshold', 'slr_estimated_thr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Experiment 8 \n",
    "\n",
    "SLR method calibrated with the ING training data set and tested on ING data\n",
    "* SLR ING-ING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T08:54:55.589455Z",
     "start_time": "2021-05-03T08:54:55.534571Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "title = 'ING calibrated SLR method / ING data set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:03:04.214718Z",
     "start_time": "2021-05-03T17:03:04.085367Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Print overall mouse metrics\"\"\"\n",
    "abrthr.print_overall_mouse_metrics(ING_data_estimations2, \n",
    "                                  _predicted_thr_col='slr_estimated_thr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:03:18.306332Z",
     "start_time": "2021-05-03T17:03:12.926755Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the threshold error normalised to the variance, overall and stimulus specific\"\"\"\n",
    "\n",
    "xlabel = 'Threshold error normalised to the variance'\n",
    "ylabel = 'Threshold assessments in percent'\n",
    "\n",
    "plot_standardised_error(ING_data_estimations2, \n",
    "                        'threshold', 'slr_estimated_thr', \n",
    "                        _title='', _xlabel=xlabel, _ylabel=ylabel)\n",
    "plot_standardised_error(ING_data_estimations2, \n",
    "                        'threshold', 'slr_estimated_thr', \n",
    "                        _title='', _xlabel=xlabel, _ylabel=ylabel, \n",
    "                        _freq_specific=True, \n",
    "                        _figsize=(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:03:41.361237Z",
     "start_time": "2021-05-03T17:03:37.647077Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the medians of the SLR estimated thresholds against the manually assessed thresholds, overall and stimulus specific\"\"\"\n",
    "\n",
    "# map 999 to 100\n",
    "df = ING_data_estimations2.copy()\n",
    "for col in ['threshold', 'slr_estimated_thr']:\n",
    "    df[col] = [100 if df.loc[idx, col] == 999 else df.loc[idx, col] for idx in df.index]\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    plot_median(df, 'slr_estimated_thr', _figsize=(21,20))\n",
    "    plot_median_stimulus_specific(df, 'slr_estimated_thr', _figsize=(30,45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T15:37:49.194213Z",
     "start_time": "2021-05-04T15:37:16.523479Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of the confusion matrix, overall and stimulus specific\"\"\"\n",
    "\n",
    "plot_confusion_matrix(ING_data_estimations2, 'slr_estimated_thr')\n",
    "plot_confusion_matrix_stimulus_specific(ING_data_estimations2, 'slr_estimated_thr', _figsize=(30,45), _title=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T15:38:41.424647Z",
     "start_time": "2021-05-04T15:38:34.940578Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Stimulus specific plots of the threshold mean as horizontal bars\"\"\"\n",
    "plot_threshold_stats(ING_data_estimations2, _columns=['threshold', 'slr_estimated_thr'])\n",
    "\n",
    "\"\"\"Stimulus specific plots of the threshold median as horizontal bars\"\"\"\n",
    "plot_threshold_stats(GMC_data_estimations2, _stat='median', _columns=['threshold', 'slr_estimated_thr'])\n",
    "\n",
    "\"\"\"Plot of threshold value boxplots grouped by threshold type\"\"\"\n",
    "plot_threshold_boxplots(ING_data_estimations2, _columns=['threshold', 'slr_estimated_thr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation curves\n",
    "\n",
    "Four threshold types are evaluated and compared using **evaluation curves**:\n",
    "\n",
    "+ the threshols predicted with neural networks ('threshold NN') \n",
    "+ the thresholds estimated by a sound level regression method ('threshold SLR')\n",
    "+ the human ground truth ('threshold manual')\n",
    "+ a constant threshold ('50')\n",
    "\n",
    "### Evaluation curves - brief description:\n",
    "\n",
    "For each ABR wave a threshold_normalized_sound_level = sound_level/threshold\n",
    "is computed.\n",
    "Then the ABR waves are sorted with respect to the threshold_normalized_sound_level in increasing order.\n",
    "\n",
    "Next we compute the strength of signal average over the N ABR-curves with smallest threshold_normalized_sound_level and plot it against N.\n",
    "\n",
    "N and the strength of signal are both normalized to have a maximum of 1.\n",
    "\n",
    "**If method A is better than method B then the evaluation curve of method A is strictly smaller then the evaluation curve of method B.**\n",
    "\n",
    "### Reasoning behind the evaluation curves:\n",
    "\n",
    "Let us assume we know the ground-truth threshold.\n",
    "Given this ground-truth threshold we can take the sample average of all super-threshold curves, as well as the sample average of all sub-threshold curves. The sample average of all super-threshold curves should give a temporal pattern, as the mice respond to a cue sound in a temporal coherent way. In contrast to this, averaging the sub-threshold ABR curves should give a constant signal, as - due to the lack of a percepted cue - the ABR curves are temporally incoherent.\n",
    "\n",
    "If we now sort all ABR cuves by their threshold normalized sound level (=sound_level/threshold) in increasing order and compute the cummulative average, we should obtain an approximately constant signal, until we start adding curves that are above the threshold. (The 'approximately' is due to the finite sample size.) If we use the ground truth threshold to do this sorting, the averaged curve will not deviate signifiantly from a constant signal before we have added all subthreshold curves to the cummulative average. However if we use a suboptimal thresholding, the averaged signal should already deviate from a constant signal before all sub-threshold curves are taken into account.\n",
    "\n",
    "Based on this, we can construct evaluation curves, that compare the quality of thresholding methods:\n",
    "We plot the (normalized) temporal variance of the averaged signal (which is zero for a constant signal) versus the total fraction of ABR curves that are contained in the cummulative average. For the ground truth threshold this curve should thus be about equal to zero until 'Normalized N' is equal to the number sub-threshold curves divided by the total number ABR curves (= sub + super threshold). After that it should increase.\n",
    "\n",
    "For suboptimal thresholds the curve should start to deviate from zero allready at a smaller level of 'Normalized N'.\n",
    "The more errorprone the thresholds are, the faster the corresponding evaluation curve deviates from zero.\n",
    "As we can see in the plots all methods start deviating from zero allready quite early.\n",
    "So none of them seems to be perfect. \n",
    "\n",
    "Nevertheless these curves allow us to judge the relative quality of different thesholding methods:\n",
    "If Method A is better than method B then the evaluation curve of method A is strictly smaller then the evaluation curve of method B. The plot shows, that an assumed constant threshold, gives the worst performance of the three thresholds compared. (**Note**, that the evaluation curves are invariant to which constant threshold is assumed: The curve looks the same for all constant thresholds.)\n",
    "We can also see that the 'human ground truth' (called 'threshold manual' in the graph) shows actually a worse performance than the ML detected thresholds ('threshold NN', 'threshold SLR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "\n",
    "* NN GMC-GMC, SLR GMC-GMC, GMC manual thresholds, dummy method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T10:41:35.125255Z",
     "start_time": "2021-05-07T10:41:32.372016Z"
    }
   },
   "outputs": [],
   "source": [
    "exp1_dataset = pd.merge(left=GMC_data, \n",
    "                        right=GMC_data_predictions1[['mouse_id', 'frequency', 'threshold', 'nn_predicted_thr']], \n",
    "                        how='left',\n",
    "                        on=['mouse_id', 'frequency', 'threshold'])\n",
    "exp1_dataset = pd.merge(left=exp1_dataset, \n",
    "                        right=GMC_data_estimations1, how='left',\n",
    "                        on=['mouse_id', 'frequency', 'threshold'])\n",
    "exp1_dataset.rename(columns={'threshold': 'threshold manual', \n",
    "                             'slr_estimated_thr': 'threshold SLR', \n",
    "                             'nn_predicted_thr': 'threshold NN'}, inplace=True)\n",
    "\n",
    "print('GMC_data rows:\\t\\t\\t%d\\nGMC_data_predictions1 rows:\\t%d\\nGMC_data_estimations1 rows:\\t%d\\nexp1_dataset rows:\\t\\t%d' % \n",
    "      (GMC_data.index.nunique(), GMC_data_predictions1.index.nunique(), GMC_data_estimations1.index.nunique(), exp1_dataset.index.nunique()))\n",
    "\n",
    "display(exp1_dataset.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T10:45:52.032162Z",
     "start_time": "2021-05-07T10:41:46.188690Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of evaluation curves\"\"\"\n",
    "plot_evaluation_curves(exp1_dataset, _xlabel=r'n/N', _ylabel=r'$S^2(n)/S^2(N)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r'$\\alpha^2$'\n",
    "#import matplotlib\n",
    "#matplotlib.rcParams['text.usetex'] = False\n",
    "#plt.xlabel(r'$\\alpha^2$')\n",
    "#plt.ylabel(r'$S^2(n)/S^2(N)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2\n",
    "   \n",
    "* NN GMC-ING, SLR GMC-ING, ING manual thresholds, dummy method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T10:51:55.178213Z",
     "start_time": "2021-05-07T10:51:49.628578Z"
    }
   },
   "outputs": [],
   "source": [
    "exp2_dataset = pd.merge(left=ING_data, \n",
    "                        right=ING_data_predictions1[['mouse_id', 'frequency', 'threshold', 'nn_predicted_thr']], \n",
    "                        how='left',\n",
    "                        on=['mouse_id', 'frequency', 'threshold'])\n",
    "exp2_dataset = pd.merge(left=exp2_dataset, \n",
    "                        right=ING_data_estimations1, how='left',\n",
    "                        on=['mouse_id', 'frequency', 'threshold'])\n",
    "exp2_dataset.rename(columns={'threshold': 'threshold manual', \n",
    "                             'slr_estimated_thr': 'threshold SLR', \n",
    "                             'nn_predicted_thr': 'threshold NN'}, inplace=True)\n",
    "\n",
    "print('ING_data rows:\\t\\t\\t%d\\nING_data_predictions1 rows:\\t%d\\nING_data_estimations1 rows:\\t%d\\nexp2_dataset rows:\\t\\t%d' % \n",
    "      (ING_data.index.nunique(), ING_data_predictions1.index.nunique(), ING_data_estimations1.index.nunique(), exp2_dataset.index.nunique()))\n",
    "\n",
    "display(exp2_dataset.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T14:12:16.145099Z",
     "start_time": "2021-05-07T10:52:25.304827Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of evaluation curves\"\"\"\n",
    "plot_evaluation_curves(exp2_dataset, _xlabel=r'n/N', _ylabel=r'$S^2(n)/S^2(N)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3\n",
    "\n",
    "* NN ING-GMC, SLR ING-GMC, GMC manual thresholds, dummy method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T14:45:26.986112Z",
     "start_time": "2021-05-07T14:45:24.268000Z"
    }
   },
   "outputs": [],
   "source": [
    "exp3_dataset = pd.merge(left=GMC_data, \n",
    "                        right=GMC_data_predictions2[['mouse_id', 'frequency', 'threshold', 'nn_predicted_thr']], \n",
    "                        how='left',\n",
    "                        on=['mouse_id', 'frequency', 'threshold'])\n",
    "exp3_dataset = pd.merge(left=exp3_dataset, \n",
    "                        right=GMC_data_estimations2, how='left',\n",
    "                        on=['mouse_id', 'frequency', 'threshold'])\n",
    "exp3_dataset.rename(columns={'threshold': 'threshold manual', \n",
    "                             'slr_estimated_thr': 'threshold SLR', \n",
    "                             'nn_predicted_thr': 'threshold NN'}, inplace=True)\n",
    "\n",
    "print('GMC_data rows:\\t\\t\\t%d\\nGMC_data_predictions2 rows:\\t%d\\nGMC_data_estimations2 rows:\\t%d\\nexp3_dataset rows:\\t\\t%d' % \n",
    "      (GMC_data.index.nunique(), GMC_data_predictions2.index.nunique(), GMC_data_estimations2.index.nunique(), exp3_dataset.index.nunique()))\n",
    "print(len(GMC_data), len(GMC_data_predictions2), len(GMC_data_estimations2), len(exp3_dataset))\n",
    "display(exp3_dataset.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T14:49:42.230903Z",
     "start_time": "2021-05-07T14:45:34.915134Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of evaluation curves\"\"\"\n",
    "plot_evaluation_curves(exp3_dataset, _xlabel=r'n/N', _ylabel=r'$S^2(n)/S^2(N)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4\n",
    "\n",
    "* NN ING-ING, SLR ING-ING, ING manual thresholds, dummy method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T15:04:00.477261Z",
     "start_time": "2021-05-07T15:03:53.586809Z"
    }
   },
   "outputs": [],
   "source": [
    "exp4_dataset = pd.merge(left=ING_data, \n",
    "                        right=ING_data_predictions2[['mouse_id', 'frequency', 'threshold', 'nn_predicted_thr']], \n",
    "                        how='left',\n",
    "                        on=['mouse_id', 'frequency', 'threshold'])\n",
    "exp4_dataset = pd.merge(left=exp4_dataset, \n",
    "                        right=ING_data_estimations2, how='left',\n",
    "                        on=['mouse_id', 'frequency', 'threshold'])\n",
    "exp4_dataset.rename(columns={'threshold': 'threshold manual', \n",
    "                             'slr_estimated_thr': 'threshold SLR', \n",
    "                             'nn_predicted_thr': 'threshold NN'}, inplace=True)\n",
    "\n",
    "print('ING_data rows:\\t\\t\\t%d\\nING_data_predictions2 rows:\\t%d\\nING_data_estimations2 rows:\\t%d\\nexp4_dataset rows:\\t\\t%d' % \n",
    "      (ING_data.index.nunique(), ING_data_predictions2.index.nunique(), ING_data_estimations2.index.nunique(), exp4_dataset.index.nunique()))\n",
    "print(len(ING_data), len(ING_data_predictions2), len(ING_data_estimations2), len(exp4_dataset))\n",
    "display(exp4_dataset.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T18:31:49.881159Z",
     "start_time": "2021-05-07T15:04:06.498839Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot of evaluation curves\"\"\"\n",
    "plot_evaluation_curves(exp4_dataset, _xlabel=r'n/N', _ylabel=r'$S^2(n)/S^2(N)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "314.85px",
    "left": "1591px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
