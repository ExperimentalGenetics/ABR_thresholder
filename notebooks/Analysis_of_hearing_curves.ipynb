{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "In high throughput mouse phenotyping found thresholds are usually aggregated on two levels: \n",
    "1. thresholds for all stimuli of one individual are aggregated to an hearing curve,\n",
    "2. hearing curves are aggregated to display mutant vs. control threshold means or medians.\n",
    "\n",
    "In this notebook, raw data was subjected to NN and SLR threshold finding for all mice in both datasets ([GMC](https://www.mouseclinic.de/) and [ING](https://journals.plos.org/plosbiology)).\n",
    "\n",
    "In a first step, all thresholds, both those determined manually and those determined automatically, are combined into a single data set.</br> \n",
    "Hearing curves are then generated for all mice in the data set to compare the differences between the hearing curves of mutants and controls using the three methods (manual, NN, SLR).\n",
    "\n",
    "To  detect  mutant mouse lines that exhibit potential biologically meaningful changes in hearing two statistical metrics are used:\n",
    "1. effect size, which descriptively spoken measures the degree of overlap between mutant and control group distributions of a stimulus-specific threshold. As no normal distribution can be assumed, **Cliffâ€™s Delta** was used, which ranges between -1 and 1.\n",
    "2. significance, using p-values resulting from a **Wilcoxon rank sum test**, defined as the probability of getting a test statistics as large or larger assuming mutant and control distributions are the same. \n",
    "\n",
    "These two metrics are displayed using so-called **volcano plots**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Set the path to the data files, for example '../data'\"\"\"\n",
    "path2data = ''\n",
    "\"\"\"Set the path to result data\"\"\"\n",
    "path2results = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Prepare the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Load ING data\n",
    "\n",
    "Load the ABR curves and the mouse phenotyping data provided by Ingham et al. as well as the NN predicted and the SLR estimated thresholds.</br>\n",
    "The files can be found under the path specified by _path2data_:\n",
    "\n",
    "* _ING/ING_abr_curves.csv_, \n",
    "* _ING/ING_mouse_data.csv_,\n",
    "\n",
    "or by _path2results_:\n",
    "\n",
    "* NN GMC-ING predictions: _ING/ING_data_GMCtrained_NN_predictions.csv_\n",
    "* NN ING-ING predictions: _ING/ING_data_INGtrained_NN_predictions.csv_\n",
    "* SLR GMC-ING estimations: _ING/ING_data_GMCcalibrated_SLR_estimations.csv_\n",
    "* SLR ING-ING estimations: _ING/ING_data_INGcalibrated_SLR_estimations.csv_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Load the ABR curves\"\"\" \n",
    "ING_data = pd.read_csv(os.path.join(path2data, 'ING', 'ING_abr_curves.csv'))\n",
    "\n",
    "\"\"\"Load the threshold predictions made by neural networks trained with GMC-data (GMCtrained_NN)\"\"\"\n",
    "ING_data_predictions1 = pd.read_csv(os.path.join(path2results, 'ING_data_GMCtrained_NN_predictions.csv'))\n",
    "\n",
    "\"\"\"Load the threshold predictions made by neural networks trained with Ingham et al.-data (INGtrained_NN)\"\"\"\n",
    "ING_data_predictions2 = pd.read_csv(os.path.join(path2results, 'ING_data_INGtrained_NN_predictions.csv'))\n",
    "\n",
    "\"\"\"Load the threshold estimations made by the SLR method calibrated on GMC training data (GMCcalibrated_SLR)\"\"\"\n",
    "ING_data_estimations1 = pd.read_csv(os.path.join(path2results, 'ING_data_GMCcalibrated_SLR_estimations.csv'))\n",
    "\n",
    "\"\"\"Load the threshold estimations made by the SLR method calibrated on Ingham et al. training data (INGcalibrated_SLR)\"\"\"\n",
    "ING_data_estimations2 = pd.read_csv(os.path.join(path2results, 'ING_data_INGcalibrated_SLR_estimations.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Load the mouse phenotyping data\"\"\"\n",
    "ING_mouse_data = pd.read_csv(os.path.join(path2data, 'ING', 'ING_mouse_data.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Load GMC data\n",
    "\n",
    "Load the ABR curves and the mouse phenotyping data from the German Mouse Clinic as well as the NN predicted and the SLR estimated thresholds.</br>\n",
    "The files can be found under the path specified by _path2data_:\n",
    "\n",
    "* _GMC/GMC_abr_curves.csv_,\n",
    "* _GMC/GMC_mouse_data.csv_,\n",
    "\n",
    "or by _path2results_:\n",
    "\n",
    "* NN GMC-GMC predictions: _GMC_data_GMCtrained_NN_predictions.csv_,\n",
    "* NN ING-GMC predictions: _GMC_data_INGtrained_NN_predictions.csv_,\n",
    "* SLR GMC-GMC estimations: _GMC_data_GMCcalibrated_SLR_estimations.csv_,\n",
    "* SLR ING-GMC estimations: _GMC_data_INGcalibrated_SLR_estimations.csv_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Load the ABR curves\"\"\"\n",
    "GMC_data = pd.read_csv(os.path.join(path2data, 'GMC', 'GMC_abr_curves.csv'))\n",
    "\n",
    "\"\"\"Load the threshold predictions made by neural networks trained with GMC data (GMCtrained_NN)\"\"\"\n",
    "GMC_data_predictions1 = pd.read_csv(os.path.join(path2results, 'GMC_data_GMCtrained_NN_predictions.csv'))\n",
    "\n",
    "\"\"\"Load the threshold predictions made by neural networks trained with Ingham et al. data (INGtrained_NN)\"\"\"\n",
    "GMC_data_predictions2 = pd.read_csv(os.path.join(path2results, 'GMC_data_INGtrained_NN_predictions.csv'))\n",
    "\n",
    "\"\"\"Load the threshold estimations made by the SLR method calibrated on GMC training data (GMCcalibrated_SLR)\"\"\"\n",
    "GMC_data_estimations1 = pd.read_csv(os.path.join(path2results, 'GMC_data_GMCcalibrated_SLR_estimations.csv'))\n",
    "\n",
    "\"\"\"Load the threshold estimations made by the SLR method calibrated on Ingham et al. training data (INGcalibrated_SLR)\"\"\"\n",
    "GMC_data_estimations2 = pd.read_csv(os.path.join(path2results, 'GMC_data_INGcalibrated_SLR_estimations.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Load the mouse phenotyping data\"\"\"\n",
    "GMC_mouse_data = pd.read_csv(os.path.join(path2data, 'GMC', 'GMC_mouse_data.csv'))\n",
    "\n",
    "\"\"\"Exclude the mice in cohorts not finished yet\"\"\"\n",
    "mouse_ids2exclude = np.load(os.path.join(path2data, 'GMC', 'GMC_mice_with_missing_ref_cohorts.npy'))\n",
    "GMC_mouse_data = GMC_mouse_data[~GMC_mouse_data.mouse_id.isin(mouse_ids2exclude)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Check if mice in reference cohorts can be found in the data set\"\"\"\n",
    "cons = GMC_mouse_data[GMC_mouse_data.cohort_type == 'control']\n",
    "muts = GMC_mouse_data[GMC_mouse_data.cohort_type == 'mutant']\n",
    "\n",
    "print('Number of controls: %i' % cons.mouse_id.nunique())\n",
    "print('Number of mutants: %i' % muts.mouse_id.nunique())\n",
    "print('Number of rows: %i' % GMC_mouse_data.index.nunique())\n",
    "\n",
    "muts[~muts.reference_cohort.isin(cons.cohort_id.unique())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Process data\n",
    "\n",
    "The resulting data set should contain the following columns:<br/> \n",
    "* **mouse_id**, \n",
    "* **sex**, \n",
    "* **cohort_type** (mut|con), \n",
    "* **gene**, \n",
    "* **exp_date** (yyyy-mm-dd), \n",
    "* **source** (GMC|ING), \n",
    "* **stimulation** (click|6|12|18|24|30), \n",
    "* **th_manual**, \n",
    "* **th_NN_GMCtrained**, \n",
    "* **th_NN_INGtrained**, \n",
    "* **th_SLR_GMCcalibrated**, \n",
    "* **th_SLR_INGcalibrated**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mouse_columns = ['mouse_id', 'sex', 'cohort_type', 'cohort_id', 'reference_cohort', 'gene', 'exp_date']\n",
    "exp_columns = ['simulation', 'th_manual', 'th_NN_GMCtrained', 'th_NN_INGtrained', 'th_SLR_GMCcalibrated', 'th_SLR_INGcalibrated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### GMC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Ensure that phenotyping data is available for all mice for which ABR curves have been measured\"\"\"\n",
    "GMC_data = GMC_data[GMC_data.mouse_id.isin(GMC_mouse_data.mouse_id.unique())]\n",
    "display(GMC_data.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Adding mouse phenotyping data for all mice with measured ABR curves\"\"\"\n",
    "print(' Number of rows: %d / mice: %d' % (GMC_data.index.nunique(), GMC_data.mouse_id.nunique()))\n",
    "GMC_merged = pd.merge(left=GMC_data[['mouse_id', 'frequency', 'threshold']].drop_duplicates(), \n",
    "                      right=GMC_mouse_data[['mouse_id', 'mouse_sex', 'cohort_type', 'cohort_id', 'reference_cohort', 'gene_symbol', 'exp_date']].drop_duplicates(), \n",
    "                      how='left', on='mouse_id')\n",
    "print(' Number of rows after merging: %d / mice: %d' % (GMC_merged.index.nunique(), GMC_merged.mouse_id.nunique()))\n",
    "\n",
    "GMC_merged.rename(columns={'mouse_sex': 'sex', 'gene_symbol': 'gene'}, inplace=True)\n",
    "GMC_merged.at[:,'source'] = 'GMC'\n",
    "GMC_merged = GMC_merged[mouse_columns + ['source', 'frequency', 'threshold']]\n",
    "\n",
    "display(GMC_merged.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Adding GMC trained NNs threshold predictions to data set\"\"\"\n",
    "print(' Number of rows: %d' % GMC_merged.index.nunique())\n",
    "GMC_merged = pd.merge(left=GMC_merged, \n",
    "                      right=GMC_data_predictions1[['mouse_id', 'frequency', 'threshold', 'nn_predicted_thr']], \n",
    "                      how='left', on=['mouse_id', 'frequency', 'threshold'])\n",
    "print(' Number of rows after merging: %d' % GMC_merged.index.nunique())\n",
    "\n",
    "GMC_merged.rename(columns={'nn_predicted_thr': 'th_NN_GMCtrained'}, inplace=True)\n",
    "display(GMC_merged.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Adding ING trained NNs threshold predictions to data set\"\"\"\n",
    "print(' Number of rows: %d' % GMC_merged.index.nunique())\n",
    "GMC_merged = pd.merge(left=GMC_merged, \n",
    "                      right=GMC_data_predictions2[['mouse_id', 'frequency', 'threshold', 'nn_predicted_thr']], \n",
    "                      how='left', on=['mouse_id', 'frequency', 'threshold'])\n",
    "print(' Number of rows after merging: %d' % GMC_merged.index.nunique())\n",
    "GMC_merged.rename(columns={'nn_predicted_thr': 'th_NN_INGtrained'}, inplace=True)\n",
    "display(GMC_merged.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Adding GMC calibrated SLR estimations to data set\"\"\"\n",
    "print(' Number of rows: %d' % GMC_merged.index.nunique())\n",
    "GMC_merged = pd.merge(left=GMC_merged, \n",
    "                      right=GMC_data_estimations1[['mouse_id', 'frequency', 'threshold', 'slr_estimated_thr']], \n",
    "                      how='left', on=['mouse_id', 'frequency', 'threshold'])\n",
    "print(' Number of rows after merging: %d' % GMC_merged.index.nunique())\n",
    "GMC_merged.rename(columns={'slr_estimated_thr': 'th_SLR_GMCcalibrated'}, inplace=True)\n",
    "display(GMC_merged.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Adding ING calibrated SLR estimations to data set\"\"\"\n",
    "print(' Number of rows: %d' % GMC_merged.index.nunique())\n",
    "GMC_merged = pd.merge(left=GMC_merged, \n",
    "                      right=GMC_data_estimations2[['mouse_id', 'frequency', 'threshold', 'slr_estimated_thr']], \n",
    "                      how='left', on=['mouse_id', 'frequency', 'threshold'])\n",
    "print(' Number of rows after merging: %d' % GMC_merged.index.nunique())\n",
    "GMC_merged.rename(columns={'slr_estimated_thr': 'th_SLR_INGcalibrated'}, inplace=True)\n",
    "display(GMC_merged.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### ING data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Adding new column for the date of experiment\"\"\"\n",
    "for idx in ING_mouse_data.index:\n",
    "    date = ING_mouse_data.at[idx, 'Test Date']\n",
    "    if date==date: \n",
    "        if date=='Test Date' or date.isdigit(): \n",
    "            ING_mouse_data.at[idx, 'exp_date'] = np.nan\n",
    "        else:\n",
    "            ING_mouse_data.at[idx, 'exp_date'] = date.replace(' 00:00:00', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Adding mouse phenotyping data for all mice with measured ABR curves\"\"\"\n",
    "print(' Number of rows: %d / mice: %d' % (ING_data.index.nunique(), ING_data.mouse_id.nunique()))\n",
    "ING_merged = pd.merge(left=ING_data[['mouse_id', 'frequency', 'threshold']].drop_duplicates(), \n",
    "                      right=ING_mouse_data[['mouse_id', 'Gene', 'exp_date', 'cohort_type']].drop_duplicates(), \n",
    "                      how='left', on='mouse_id')\n",
    "print(' Number of rows after merging: %d / mice: %d' % (ING_merged.index.nunique(), ING_merged.mouse_id.nunique()))\n",
    "\n",
    "ING_merged.rename(columns={'Gene': 'gene'}, inplace=True)\n",
    "ING_merged.at[:,'source'] = 'ING'\n",
    "ING_merged.at[:,'sex'] = np.nan\n",
    "ING_merged.at[:,'cohort_id'] = np.nan\n",
    "ING_merged.at[:,'reference_cohort'] = np.nan\n",
    "\n",
    "ING_merged = ING_merged[mouse_columns + ['source', 'frequency', 'threshold']]\n",
    "\n",
    "display(ING_merged.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Adding GMC trained NNs predictions to data set\"\"\"\n",
    "print(' Number of rows: %d' % ING_merged.index.nunique())\n",
    "ING_merged = pd.merge(left=ING_merged, \n",
    "                      right=ING_data_predictions1[['mouse_id', 'frequency', 'threshold', 'nn_predicted_thr']], \n",
    "                      how='left', on=['mouse_id', 'frequency', 'threshold'])\n",
    "print(' Number of rowy after merging: %d' % ING_merged.index.nunique())\n",
    "\n",
    "ING_merged.rename(columns={'nn_predicted_thr': 'th_NN_GMCtrained'}, inplace=True)\n",
    "display(ING_merged.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Adding ING trained NNs predictions to data set\"\"\"\n",
    "print(' Number of rows: %d' % ING_merged.index.nunique())\n",
    "ING_merged = pd.merge(left=ING_merged, \n",
    "                      right=ING_data_predictions2[['mouse_id', 'frequency', 'threshold', 'nn_predicted_thr']], \n",
    "                      how='left', on=['mouse_id', 'frequency', 'threshold'])\n",
    "print(' Number of rows after merging: %d' % ING_merged.index.nunique())\n",
    "\n",
    "ING_merged.rename(columns={'nn_predicted_thr': 'th_NN_INGtrained'}, inplace=True)\n",
    "display(ING_merged.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Adding GMC calibrated SLR estimations to data set\"\"\"\n",
    "print(' Number of rows: %d' % ING_merged.index.nunique())\n",
    "ING_merged = pd.merge(left=ING_merged, \n",
    "                      right=ING_data_estimations1[['mouse_id', 'frequency', 'threshold', 'slr_estimated_thr']], \n",
    "                      how='left', on=['mouse_id', 'frequency', 'threshold'])\n",
    "print(' Number of rows after merging: %d' % ING_merged.index.nunique())\n",
    "\n",
    "ING_merged.rename(columns={'slr_estimated_thr': 'th_SLR_GMCcalibrated'}, inplace=True)\n",
    "display(ING_merged.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Adding ING calibrated SLR estimations to data set\"\"\"\n",
    "print(' Number of rows: %d' % ING_merged.index.nunique())\n",
    "ING_merged = pd.merge(left=ING_merged, \n",
    "                      right=ING_data_estimations2[['mouse_id', 'frequency', 'threshold', 'slr_estimated_thr']], \n",
    "                      how='left', on=['mouse_id', 'frequency', 'threshold'])\n",
    "print(' Number of rows after merging: %d' % ING_merged.index.nunique())\n",
    "\n",
    "ING_merged.rename(columns={'slr_estimated_thr': 'th_SLR_INGcalibrated'}, inplace=True)\n",
    "display(ING_merged.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Save the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Merge GMC and ING data sets\"\"\"\n",
    "merged_data = pd.concat([GMC_merged, ING_merged], ignore_index=True)\n",
    "display(merged_data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for idx in merged_data.index:\n",
    "    freq = merged_data.at[idx, 'frequency']\n",
    "    if freq == 100:\n",
    "        merged_data.at[idx, 'stimulation'] = 'click'\n",
    "    else:\n",
    "        merged_data.at[idx, 'stimulation'] = int(freq/1000)\n",
    "    cohort_type = merged_data.at[idx, 'cohort_type']\n",
    "    if cohort_type == 'control': \n",
    "        merged_data.at[idx, 'cohort_type'] = 'con'\n",
    "    elif cohort_type == 'mutant': \n",
    "        merged_data.at[idx, 'cohort_type'] = 'mut'\n",
    "display(merged_data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for idx in merged_data.index:\n",
    "    cohort_type = merged_data.at[idx, 'cohort_type']\n",
    "    if cohort_type == 'con': \n",
    "        merged_data.at[idx, 'gene'] = np.nan\n",
    "# merged_data = merged_data[merged_data.columns.drop('frequency')]\n",
    "merged_data.rename(columns={'threshold': 'th_manual'}, inplace=True)\n",
    "display(merged_data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "merged_data.to_csv(os.path.join(path2data, 'data4hearing_curves_analysis.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hearing curve analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(path2data, 'data4hearing_curves_analysis.csv'))\n",
    "display(data.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5,
     27,
     33,
     43
    ]
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 16]\n",
    "\n",
    "colors = {'th_manual': '#004488'\n",
    "          , 'th_manual_mut': '#004488'\n",
    "          , 'th_manual_con': '#6699CC' \n",
    "          , 'th_manual_ref_con': '#332288'\n",
    "          , 'th_manual_all_ref_cons': '#88CCEE'\n",
    "          , 'th_NN_GMCtrained': '#225522'\n",
    "          , 'th_NN_GMCtrained_mut': '#225522'\n",
    "          , 'th_NN_GMCtrained_con': '#5AAE61'\n",
    "          , 'th_NN_GMCtrained_ref_con': '#225555'\n",
    "          , 'th_NN_GMCtrained_all_ref_cons': '#CCEEFF'\n",
    "          , 'th_SLR_GMCcalibrated': '#B2182B'\n",
    "          , 'th_SLR_GMCcalibrated_mut': '#B2182B'\n",
    "          , 'th_SLR_GMCcalibrated_con': '#D6604D'\n",
    "          , 'th_SLR_GMCcalibrated_ref_con': '#882255'\n",
    "          , 'th_SLR_GMCcalibrated_all_ref_cons': '#FFCCCC'\n",
    "          , 'th_NN_INGtrained': '#225522'\n",
    "          , 'th_NN_INGtrained_mut': '#225522'\n",
    "          , 'th_NN_INGtrained_con': '#5AAE61'\n",
    "          , 'th_SLR_INGcalibrated': '#B2182B'\n",
    "          , 'th_SLR_INGcalibrated_mut': '#B2182B'\n",
    "          , 'th_SLR_INGcalibrated_con': '#D6604D'}\n",
    "\n",
    "std_colors = {'th_manual': '#004488'\n",
    "             , 'th_NN_GMCtrained': '#CCDDAA'\n",
    "             , 'th_NN_INGtrained': '#FDDBC7'\n",
    "             , 'th_SLR_GMCcalibrated': '#FFCCCC'\n",
    "             , 'th_SLR_INGcalibrated': '#EEEEBB'}\n",
    "\n",
    "markers = {'con': 'o'\n",
    "           , 'ref_con': 's'\n",
    "           , 'mut': '^'\n",
    "           , 'th_manual': 'o'\n",
    "           , 'th_NN_GMCtrained': '^'\n",
    "           , 'th_SLR_GMCcalibrated': '*'\n",
    "           , 'th_manual': 'o'\n",
    "           , 'th_NN_INGtrained': '^'\n",
    "           , 'th_SLR_INGcalibrated': '*'}\n",
    "\n",
    "linestyles = {'mut': 'solid'\n",
    "              , 'con': 'dashed'\n",
    "              , 'ref_con': 'dashdot'\n",
    "              , 'th_manual': 'solid'\n",
    "              , 'th_NN_GMCtrained': 'dotted'\n",
    "              , 'th_SLR_GMCcalibrated': 'dashdot'\n",
    "              , 'th_NN_INGtrained': 'dotted'\n",
    "              , 'th_SLR_INGcalibrated': 'dashdot'}\n",
    "\n",
    "labels = {'th_manual': 'Manually assigned thresholds' \n",
    "          , 'th_NN_GMCtrained': 'Thresholds predicted by GMC trained NNs'\n",
    "          , 'th_NN_INGtrained': 'Thresholds predicted by ING trained NNs'\n",
    "          , 'th_SLR_GMCcalibrated': 'Thresholds estimated by GMC calibrated SLR'\n",
    "          , 'th_SLR_INGcalibrated': 'Thresholds estimated by ING calibrated SLR'}\n",
    "\n",
    "title_fontsize=20\n",
    "\n",
    "\"\"\"Quantile calculation\"\"\"\n",
    "def q1(x):\n",
    "    return x.quantile(0.25)\n",
    "\n",
    "def q3(x):\n",
    "    return x.quantile(0.75)\n",
    "\n",
    "def q(x, val):\n",
    "    return x.quantile(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_result_file_names(_gene, _formats, _data_source): \n",
    "    \n",
    "    \"\"\"\n",
    "    Sets the path to the files in which the visualisation plots are to be saved.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        _gene: string\n",
    "            A given gene name indicating the name of the folder.\n",
    "            \n",
    "        _formats: list\n",
    "            The file formats in which to save the plots.\n",
    "            \n",
    "        _data_source: string\n",
    "            The source of the data: GMC or ING.\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "        The folder and file names.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if ' / ' in _gene:\n",
    "        gene_name = str(_gene).replace(' / ', '_').strip()\n",
    "    elif ' ' in _gene: \n",
    "        gene_name = str(_gene).replace(' ', '_').strip()\n",
    "    elif ':' in _gene:\n",
    "        gene_name = str(_gene).replace(':', '_').strip()\n",
    "    else: \n",
    "        gene_name = str(_gene).strip()\n",
    "    \n",
    "    gene_dir = {}\n",
    "    file = {}\n",
    "    \n",
    "    dir_name = 'hearing_curve_analysis' \n",
    "    \n",
    "    for fmt in _formats:\n",
    "        gene_dir[fmt] = os.path.join(path2results, dir_name, str(fmt)+'_format', _data_source)\n",
    "        if not os.path.exists(gene_dir[fmt]):\n",
    "            os.mkdir(gene_dir[fmt])\n",
    "        gene_dir[fmt] = os.path.join(gene_dir[fmt], gene_name)\n",
    "        if not os.path.exists(gene_dir[fmt]):\n",
    "            os.mkdir(gene_dir[fmt])\n",
    "        file[fmt] = os.path.join(gene_dir[fmt], gene_name + '_thr_median')\n",
    "    \n",
    "    return gene_dir,file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_thresholds4gene(_gene, _th_cols, _data, _colors, _markers, _linestyles, _labels, \n",
    "                         _dodge=True, _fontsize=16, _markersize=7, _markerscale=1.5, \n",
    "                         _cohort_type=True, _estimator=np.mean, _ci='sd', _fst_quantile=0.05, _last_quantile=0.95, \n",
    "                         _mouse_id=None, \n",
    "                         _legend_outside=False, _figlegend=False, _xlabel=None, _ylabel=None, \n",
    "                         _fig=None, _ax=None):\n",
    "    \"\"\"\n",
    "    Plots hearing curves for a given gene in the data set and returns the legend elements of the plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    if _ax is not None and _fig is not None:\n",
    "        fig = _fig\n",
    "        ax = _ax\n",
    "    else:\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "    _data = _data.copy()\n",
    "    \n",
    "    for col in _th_cols:\n",
    "        _data[col] = [100 if _data.at[idx, col] == 999 else _data.at[idx, col] for idx in _data.index]\n",
    "    \n",
    "    th = re.compile('th_*')\n",
    "    all_th_columns = [col for col in _data.columns if th.match(col)]\n",
    "    \n",
    "    \"\"\"create dataframe with the gene mutants and the corresponding controls\"\"\"\n",
    "    gene_data = _data[_data.gene == _gene]\n",
    "    if _cohort_type:\n",
    "        if _data.source.unique().squeeze() == 'GMC':\n",
    "            gene_data = pd.concat([gene_data, _data[_data.cohort_id.isin(gene_data.reference_cohort.unique())]])\n",
    "            gene_data = gene_data.replace('con', 'ref_con')\n",
    "        if _data.source.unique().squeeze() == 'ING' and 'pipeline' in _data.columns: \n",
    "            gene_data = pd.concat([gene_data, _data[(_data.cohort_type == 'con') & _data.pipeline.isin(gene_data.pipeline.unique())]])\n",
    "        else:\n",
    "            gene_data = pd.concat([gene_data, _data[_data.cohort_type == 'con']])\n",
    "        gene_data = gene_data.reset_index(drop=True)\n",
    "    \n",
    "    \"\"\"add threshold type column\"\"\"\n",
    "    th_data = []\n",
    "    for col in _th_cols:\n",
    "        mouse_columns = list(gene_data.columns.drop(all_th_columns))\n",
    "        mouse_columns.append(str(col)) \n",
    "        \n",
    "        tmp_data = gene_data[mouse_columns]\n",
    "        tmp_data = tmp_data.rename(columns={col: 'th_value'})\n",
    "        \n",
    "        for idx in tmp_data.index:\n",
    "            stim = tmp_data.at[idx, 'stimulation']\n",
    "            coh_type = tmp_data.at[idx, 'cohort_type']\n",
    "            if stim == 'click': \n",
    "                if _cohort_type:\n",
    "                    tmp_data.at[idx, 'th_type'] = col+'_con_click' if coh_type=='con' else col+'_ref_con_click' if coh_type=='ref_con' else col+'_mut_click'\n",
    "                else:\n",
    "                    tmp_data.at[idx, 'th_type'] = col+'_click'\n",
    "            else:\n",
    "                if _cohort_type:\n",
    "                    tmp_data.at[idx, 'th_type'] = col+'_con_freq' if coh_type=='con' else col+'_ref_con_freq' if coh_type=='ref_con' else col + '_mut_freq'\n",
    "                else:\n",
    "                    tmp_data.at[idx, 'th_type'] = col+'_freq'\n",
    "        th_data.append(tmp_data.copy())  \n",
    "    gene_data1 = pd.concat(th_data)\n",
    "    \n",
    "    \"\"\"create legend elements\"\"\"\n",
    "    legend_elements = []\n",
    "    hue_order = []\n",
    "    palette = {}\n",
    "    markers = []\n",
    "    linestyles = []\n",
    "    \n",
    "    if _data.source.unique().squeeze() == 'GMC':\n",
    "        cohort_types = ['mut', 'ref_con', 'con']\n",
    "    else:\n",
    "        cohort_types = ['mut', 'con']\n",
    "    \n",
    "    if _cohort_type: \n",
    "        for col in _th_cols: \n",
    "            for coh_type in cohort_types:   \n",
    "                legend_elements.append(Line2D([0], [0], color=_colors[col + '_' + coh_type], marker=_markers[coh_type], linestyle=_linestyles[coh_type], \n",
    "                                              ms=_markersize, label='%s%s %s (n=%d)' % (col + ' - ' if len(_th_cols)>1 else '', \n",
    "                                                                                        'all controls' if coh_type=='con' else _gene+' reference controls' if coh_type=='ref_con' else _gene+' mutants', \n",
    "                                                                                        'mean' if _estimator==np.mean else 'median', gene_data[gene_data.cohort_type==coh_type].mouse_id.nunique())))\n",
    "                for ho in [col + '_' + coh_type + '_click', col + '_' + coh_type + '_freq']:\n",
    "                    hue_order.append(ho)\n",
    "        \n",
    "        for ho in hue_order:\n",
    "            if 'mut' in ho: \n",
    "                for col in _th_cols:\n",
    "                    if col in ho:\n",
    "                        palette[ho] = _colors[col + '_mut'] \n",
    "                    markers.append(_markers['mut'])\n",
    "                    linestyles.append(_linestyles['mut'])\n",
    "            elif 'ref_con' in ho: \n",
    "                for col in _th_cols:\n",
    "                    if col in ho:\n",
    "                        palette[ho] = _colors[col + '_ref_con'] \n",
    "                    markers.append(_markers['ref_con'])\n",
    "                    linestyles.append(_linestyles['ref_con'])\n",
    "            else: \n",
    "                for col in _th_cols:\n",
    "                    if col in ho:\n",
    "                        palette[ho] = _colors[col + '_con'] \n",
    "                    markers.append(_markers['con'])\n",
    "                    linestyles.append(_linestyles['con'])\n",
    "    else:\n",
    "        for col in _th_cols: \n",
    "            if _mouse_id is None: \n",
    "                if len(_th_cols)>1:\n",
    "                    legend_lbl = '%s - %s' % (col, 'mean' if _estimator==np.mean else 'median')\n",
    "                else: \n",
    "                    legend_lbl = '%s (n=%d)' % ('mean' if _estimator==np.mean else 'median', gene_data.mouse_id.nunique())\n",
    "            else: \n",
    "                legend_lbl = '%s' % col\n",
    "            legend_elements.append(Line2D([0], [0], color=_colors[col+'_mut'], marker=_markers[col], \n",
    "                                          linestyle=_linestyles['mut'], ms=_markersize, \n",
    "                                          label=legend_lbl))\n",
    "            for ho in [col + '_click', col + '_freq']:\n",
    "                hue_order.append(ho)\n",
    "        for ho in hue_order:\n",
    "            for col in _th_cols:\n",
    "                if col in ho:\n",
    "                    palette[ho] = _colors[col+'_mut'] \n",
    "                    markers.append(_markers[col])\n",
    "                    linestyles.append(_linestyles['mut'])\n",
    "    \n",
    "    \n",
    "    if _mouse_id is None:                \n",
    "        sns.pointplot(x='stimulation', y='th_value', data=gene_data1, \n",
    "                      hue='th_type', hue_order=hue_order, dodge=_dodge, legend=False, \n",
    "                      estimator=_estimator, ci=_ci, capsize=.1, errwidth=2, label=hue_order,\n",
    "                      markers=markers, scale=_markerscale, linestyles=linestyles, palette=palette, \n",
    "                      ax=ax)\n",
    "    elif _mouse_id in gene_data1.mouse_id.unique(): \n",
    "        sns.pointplot(x='stimulation', y='th_value', data=gene_data1[gene_data1.mouse_id == _mouse_id], \n",
    "                      hue='th_type', hue_order=hue_order, dodge=_dodge, legend=False, \n",
    "                      estimator=_estimator, ci=_ci, capsize=.1, errwidth=2, label=hue_order,\n",
    "                      markers=markers, scale=_markerscale, linestyles=linestyles, palette=palette, \n",
    "                      ax=ax)\n",
    "    \n",
    "    _alpha = 0.1\n",
    "    \n",
    "    if _estimator == np.mean:\n",
    "        for col in _th_cols:\n",
    "            if _cohort_type:\n",
    "                bounds = gene_data[gene_data.cohort_type=='con'].groupby(['stimulation', 'frequency'])[col].agg(['mean', 'std']).reset_index().sort_values(by='frequency')\n",
    "            else: \n",
    "                bounds = gene_data.groupby(['stimulation', 'frequency'])[col].agg(['mean', 'std']).reset_index().sort_values(by='frequency')\n",
    "            \n",
    "            x = bounds.iloc[:,0]\n",
    "            collection1 = ax.fill_between(np.arange(-0.15, 0.15, 0.01), \n",
    "                                              bounds.iloc[:,2][5] - bounds.iloc[:,3][5],\n",
    "                                              bounds.iloc[:,2][5] + bounds.iloc[:,3][5], alpha=_alpha,\n",
    "                                              facecolor=_colors[col])\n",
    "            collection1.set_zorder(0)\n",
    "            collection2 = ax.fill_between(x, \n",
    "                                              bounds.iloc[:,2] - bounds.iloc[:,3],\n",
    "                                              bounds.iloc[:,2] + bounds.iloc[:,3], alpha=_alpha, label='std dev con', \n",
    "                                              where=[False if x[idx] == 'click' else True for idx in x.index],\n",
    "                                              facecolor=_colors[col]) \n",
    "            collection2.set_zorder(0)\n",
    "            \n",
    "            if len(_th_cols)>1:\n",
    "                legend_lbl=\"%s - %sstandard deviation\" % (col, 'all controls ' if _cohort_type else '')\n",
    "                if _mouse_id: \n",
    "                    legend_lbl = legend_lbl + ' (n=%d)' % (gene_data[gene_data.cohort_type == 'con'].mouse_id.nunique() if _cohort_type else gene_data.mouse_id.nunique())\n",
    "            else:\n",
    "                legend_lbl=\"%sstandard deviation (n=%d)\" % ('all controls ' if _cohort_type else '', \n",
    "                                                                 gene_data[gene_data.cohort_type == 'con'].mouse_id.nunique() if _cohort_type else gene_data.mouse_id.nunique())\n",
    "            legend_elements.append(\n",
    "                Patch(facecolor=_colors[col], alpha=_alpha, edgecolor=_colors[col], \n",
    "                      label=legend_lbl))\n",
    "    elif _estimator == np.median: \n",
    "        step = _dodge/(len(ax.get_lines())-1)\n",
    "        st = -_dodge/2\n",
    "        steps = []\n",
    "        while st <= 0.05:\n",
    "            steps.append(st)\n",
    "            st += step\n",
    "        j = 0\n",
    "        for col in _th_cols:\n",
    "            \n",
    "            if _cohort_type: \n",
    "                bounds = gene_data[_data.cohort_type=='con'].groupby(['stimulation', 'frequency'])[col].quantile((_fst_quantile,_last_quantile)).unstack().reset_index().sort_values(by='frequency')\n",
    "            else:\n",
    "                bounds = gene_data.groupby(['stimulation', 'frequency'])[col].quantile((_fst_quantile,_last_quantile)).unstack().reset_index().sort_values(by='frequency')\n",
    "            \n",
    "            x = bounds.iloc[:,0]\n",
    "            collection1 = ax.fill_between(np.arange(-0.15, 0.15, 0.01), \n",
    "                                          bounds.iloc[:,2][bounds.iloc[:,0].index[0]], bounds.iloc[:,3][bounds.iloc[:,0].index[0]], \n",
    "                                          alpha=_alpha, facecolor=_colors[col]) \n",
    "            collection1.set_zorder(0)\n",
    "            collection2 = ax.fill_between(bounds.iloc[:,0], \n",
    "                                          bounds.iloc[:,2], bounds.iloc[:,3], \n",
    "                                          alpha=_alpha, \n",
    "                                          where=[False if x[idx] == 'click' else True for idx in x.index],\n",
    "                                          facecolor=_colors[col]) \n",
    "            collection2.set_zorder(0)\n",
    "            \n",
    "            if len(_th_cols)>1:\n",
    "                legend_lbl=\"%s - %s[5;95] percentile range\" % (col, 'all controls ' if _cohort_type else '')\n",
    "                if _mouse_id: \n",
    "                    legend_lbl = legend_lbl + ' (n=%d)' % (gene_data[gene_data.cohort_type == 'con'].mouse_id.nunique() if _cohort_type else gene_data.mouse_id.nunique())\n",
    "            else:\n",
    "                legend_lbl=\"%s[5;95] percentile range (n=%d)\" % ('all controls ' if _cohort_type else '', \n",
    "                                                                 gene_data[gene_data.cohort_type == 'con'].mouse_id.nunique() if _cohort_type else gene_data.mouse_id.nunique())\n",
    "            legend_elements.append(\n",
    "                Patch(facecolor=_colors[col], alpha=_alpha, edgecolor=_colors[col], \n",
    "                      label=legend_lbl))\n",
    "             \n",
    "            if _cohort_type:   \n",
    "                for coh_type in cohort_types: \n",
    "                    bounds1 = gene_data[gene_data.cohort_type==coh_type].groupby(['stimulation', 'frequency'])[col].quantile((0.25,0.75)).unstack().reset_index().sort_values(by='frequency')\n",
    "                    i = 0\n",
    "                    for idx in bounds1.index:\n",
    "                        x = i+steps[j]\n",
    "                        if i == 0: \n",
    "                            j += 1\n",
    "                        ymin = bounds1.at[idx,0.25]\n",
    "                        ymax = bounds1.at[idx,0.75]\n",
    "                        vline = ax.vlines(x, ymin=ymin, ymax=ymax, color=_colors[col + '_' + coh_type], lw=1)\n",
    "                        vline.set_zorder(0)\n",
    "                        hline1 = ax.hlines(ymin, xmin=x-0.05, xmax=x+0.05, color=_colors[col + '_' + coh_type], lw=1)\n",
    "                        hline2 = ax.hlines(ymax, xmin=x-0.05, xmax=x+0.05, color=_colors[col + '_' + coh_type], lw=1)\n",
    "                        i += 1\n",
    "                    j += 1\n",
    "            else:\n",
    "                 if _mouse_id is None:\n",
    "                    bounds1 = gene_data.groupby(['stimulation', 'frequency'])[col].quantile((0.25,0.75)).unstack().reset_index().sort_values(by='frequency')\n",
    "                    i = 0\n",
    "                    for idx in bounds1.index:\n",
    "                        x = i+steps[j]\n",
    "                        if i == 0: \n",
    "                            j += 1\n",
    "                        ymin = bounds1.at[idx,0.25]\n",
    "                        ymax = bounds1.at[idx,0.75]\n",
    "                        vline = ax.vlines(x, ymin=ymin, ymax=ymax, color=_colors[col], lw=1)\n",
    "                        vline.set_zorder(0)\n",
    "                        hline1 = ax.hlines(ymin, xmin=x-0.05, xmax=x+0.05, color=_colors[col], lw=1)\n",
    "                        hline2 = ax.hlines(ymax, xmin=x-0.05, xmax=x+0.05, color=_colors[col], lw=1)\n",
    "                        i += 1\n",
    "                    j += 1\n",
    "    \n",
    "    plt.setp(ax.lines,linewidth=1)\n",
    "    if not _figlegend:\n",
    "        if _legend_outside:\n",
    "            ax.legend(handles=legend_elements, loc='lower left', bbox_to_anchor= (0.0, 1.01), ncol=2,\n",
    "                      borderaxespad=0, frameon=False, fontsize=_fontsize)\n",
    "        else: \n",
    "            ax.legend(handles=legend_elements, loc='upper left', frameon=False, fontsize=_fontsize-8)\n",
    "    else:\n",
    "        ax.legend(handles=[])\n",
    "    \n",
    "    ax.set_ylim(0, 120)   \n",
    "    ax.set_ylabel(_ylabel, fontsize=_fontsize)\n",
    "    ax.set_xlabel(_xlabel, fontsize=_fontsize, labelpad=20)\n",
    "    xticklabels = []\n",
    "    if ax.get_xticklabels():\n",
    "        for lb in ax.get_xticklabels():\n",
    "            txt = lb.get_text()\n",
    "            if txt == 'click': \n",
    "                xticklabels.append(txt)\n",
    "            else:\n",
    "                xticklabels.append('%ikHz' % int(float(txt)))\n",
    "    ax.set_xticklabels(xticklabels)\n",
    "    ax.set_yticks([ytick for ytick in range(20,120,20)])\n",
    "    ax.tick_params(axis='both', which='major', labelsize=_fontsize)\n",
    "        \n",
    "    return legend_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def plot_gene_thresholds2file(_gene, _data, _labels, \n",
    "                              _fontsize=40, _xlabel='stimulation', _ylabel='threshold [dB]', \n",
    "                              _file_output_only=False):\n",
    "    \"\"\"\n",
    "    Plots hearing curves for a given gene in the data set, taking into account the manually assessed, NN predicted and SLR estimated thresholds. \n",
    "    \"\"\"\n",
    "    \n",
    "    data_source = str(_data.source.unique().squeeze())\n",
    "    \n",
    "    muts = _data[_data.cohort_type == 'mut']\n",
    "    \n",
    "    cols = ['th_manual', 'th_NN_'+data_source+'trained', 'th_SLR_'+data_source+'calibrated']\n",
    "    titles = {}\n",
    "    for col in cols:\n",
    "        titles[col] = '%s\\n(%s)' % (_labels[col], col)\n",
    "    \n",
    "    text = ['A', 'B', 'C', 'D']\n",
    "    \n",
    "    gene = _gene\n",
    "    dir_names, file_names = get_result_file_names(gene, ['pdf', 'jpg'], data_source)\n",
    "    \n",
    "    markersize = 10\n",
    "    markerscale = 2\n",
    "    \n",
    "    with PdfPages(file_names['pdf']+'.pdf') as pdf:\n",
    "        \n",
    "        nrows = 2\n",
    "        ncols = 2\n",
    "\n",
    "        fig1, axs1 = plt.subplots(nrows, ncols, figsize=(ncols*15,nrows*13), sharey=True, sharex=True, constrained_layout=True) #(60,48)\n",
    "\n",
    "        nrow = -1\n",
    "        ncol = 0\n",
    "        for idx,col in enumerate(cols):\n",
    "    \n",
    "            xlabel = _xlabel\n",
    "            ylabel = _ylabel\n",
    "    \n",
    "            ncol = idx%ncols\n",
    "    \n",
    "            if ncol == 0:\n",
    "                nrow += 1\n",
    "            else:\n",
    "                ylabel = None\n",
    "    \n",
    "            if nrow == 0:\n",
    "                xlabel = None\n",
    "    \n",
    "            plot_thresholds4gene(gene, [col], _data, colors, markers, linestyles, labels, \n",
    "                                 _estimator=np.median, _ci=None, _dodge=0.1, \n",
    "                                 _fontsize=_fontsize, _markersize=markersize, _markerscale=markerscale, \n",
    "                                 _xlabel=xlabel, _ylabel=ylabel, _fig=fig1, _ax=axs1[nrow,ncol])\n",
    "            \n",
    "            axs1[nrow, ncol].set_title(titles[col], fontsize=_fontsize+5, y=1.01)\n",
    "            axs1[nrow, ncol].text(-0.3, 3., text[idx], fontsize=_fontsize+10, fontweight='bold')\n",
    "            axs1[nrow, ncol].grid(zorder=0, color='lightgray')    \n",
    "            \n",
    "            ncol += 1\n",
    "     \n",
    "        plot_thresholds4gene(gene, cols, _data, colors, markers, linestyles, labels, \n",
    "                             _cohort_type=False, _estimator=np.median, _ci=None, _dodge=0.1,\n",
    "                             _fontsize=_fontsize, _markersize=markersize, _markerscale=markerscale, \n",
    "                             _xlabel=xlabel, _fig=fig1, _ax=axs1[nrow,ncol])\n",
    "        \n",
    "        axs1[nrow,ncol].set_title(\n",
    "            'Method comparison for %s mutants (n=%d)' % (_gene, _data[(_data.gene==gene)&(_data.cohort_type=='mut')].mouse_id.nunique()), \n",
    "            fontsize=_fontsize+5, y=1.01)\n",
    "        axs1[nrow, ncol].text(-0.3, 3., text[-1], fontsize=_fontsize+10, fontweight='bold')\n",
    "        axs1[nrow, ncol].grid(zorder=0, color='lightgray')\n",
    "\n",
    "#         fig1.suptitle(gene, y=0.99, fontsize=_fontsize+5, fontweight='bold')\n",
    "        fig1.tight_layout()    \n",
    "        \n",
    "        pdf.savefig(fig1, bbox_inches = 'tight', papertype = 'letter')\n",
    "        fig1.savefig(file_names['jpg']+'_gene.jpg')\n",
    "        if _file_output_only:\n",
    "            plt.close()\n",
    "        \n",
    "        ################################################################################################\n",
    "        \n",
    "        mice = _data[_data.gene == gene]['mouse_id']\n",
    "        noofmice = mice.nunique()\n",
    "\n",
    "        ncols = 4\n",
    "        if noofmice > ncols:\n",
    "            if noofmice%2 == 0:\n",
    "                nrows = int(noofmice/ncols)\n",
    "            else:\n",
    "                nrows = int(noofmice/ncols) + 1\n",
    "        else:\n",
    "            nrows = 1\n",
    "\n",
    "        fig2, axs2 = plt.subplots(nrows, ncols, figsize=(ncols*15,nrows*12), sharey=True, sharex=True)\n",
    "        \n",
    "        axes = []\n",
    "        if nrows == 1:\n",
    "            for ax in axs2:\n",
    "                axes.append(ax)\n",
    "            legend_bbox = (.035, 1.24)\n",
    "        else: \n",
    "            for ax1 in axs2: \n",
    "                for ax2 in ax1:\n",
    "                    axes.append(ax2)\n",
    "            legend_bbox = (.035, 1.06)\n",
    "         \n",
    "        for idx,ax in enumerate(axes):\n",
    "        \n",
    "            xlabel = _xlabel\n",
    "            ylabel = _ylabel\n",
    "        \n",
    "            if idx%ncols > 0:\n",
    "                ylabel = None\n",
    "                    \n",
    "            if idx < nrows*ncols - ncols:\n",
    "                xlabel = None \n",
    "                \n",
    "            if idx < noofmice:\n",
    "                mouseid = mice.unique()[idx]\n",
    "                    \n",
    "                legend_elements = plot_thresholds4gene(gene, cols, muts, colors, markers, linestyles, labels, \n",
    "                                                       _cohort_type=False, _estimator=np.median, _ci=None, _dodge=0.1, _mouse_id=mouseid,\n",
    "                                                       _markersize=markersize, _markerscale=markerscale, \n",
    "                                                       _fontsize=_fontsize, _figlegend=True, _legend_outside=True, \n",
    "                                                       _xlabel=xlabel, _ylabel=ylabel, _fig=fig2, _ax=ax)  \n",
    "                ax.text(.01, 110, 'mouse_id = %s' % mouseid, fontsize=_fontsize-5)\n",
    "    \n",
    "            ax.set_ylabel(ylabel, fontsize=_fontsize-5)\n",
    "            ax.set_xlabel(xlabel, fontsize=_fontsize-5, labelpad=20)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=_fontsize-5)\n",
    "            ax.grid(zorder=0, color='lightgray')    \n",
    "        \n",
    "        fig2.legend(handles=legend_elements, loc='lower left', bbox_to_anchor=(.021, 1.01), ncol=2,\n",
    "                    borderaxespad=0, fancybox=True, fontsize=_fontsize-5)\n",
    "        fig2.subplots_adjust(top=0.9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        pdf.savefig(fig2, bbox_inches = 'tight', papertype = 'letter')\n",
    "        fig2.savefig(file_names['jpg']+'_mice.jpg', bbox_inches = 'tight', papertype = 'letter')\n",
    "        if _file_output_only:\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_curves_per_mouse(_mouse_id, _data, _freq, _thr_cols, \n",
    "                          _fontsize, _fig, _ax, _colors, _linestyles, _markers, \n",
    "                          _legend_elements, _cohort_type='mut'):\n",
    "    \"\"\"\n",
    "    Plots the ABR curves at different sound levels for a given mouse identifier and stimulus frequency.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        _mouse_id: int (GMC) or string (ING)\n",
    "            A given mouse identifier contained in _data.\n",
    "            \n",
    "        _data: pandas-data-frame\n",
    "            It contains time series for ABR curves. \n",
    "            It must contain columns for frequency ('frequency') and sound level ('sound_level'). \n",
    "            \n",
    "        _freq: int\n",
    "            A given stimulus frequency.\n",
    "            \n",
    "        _thr_cols: list \n",
    "            The names of the columns with manually assessed, NN predicted and SLR estimated thresholds.\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "        The current list of legend elements.\n",
    "    \"\"\"\n",
    "\n",
    "    data_cols = ['t' + str(i) for i in range(0, 1000)]\n",
    "    \n",
    "    sound_levels = _data['sound_level'].unique()\n",
    "    df = _data[_data.mouse_id == _mouse_id]\n",
    "\n",
    "    \"\"\"Calculating the thresholds to highlight them on the resulting plot\"\"\"\n",
    "    nn_thr = None\n",
    "    slr_thr = None\n",
    "    human_thr = None\n",
    "    \n",
    "    thr_manual = _thr_cols[0]\n",
    "    thr_NN = _thr_cols[1]\n",
    "    thr_SLR = _thr_cols[2]\n",
    "    \n",
    "    thr = df[df['frequency'] == _freq][thr_NN].unique()\n",
    "    if len(thr) > 0:\n",
    "        nn_thr = thr[0]\n",
    "    thr = df[df['frequency'] == _freq][thr_SLR].unique()\n",
    "    if len(thr) > 0:\n",
    "        slr_thr = thr[0]\n",
    "    thr = df[df['frequency'] == _freq][thr_manual].unique()\n",
    "    if len(thr) > 0:\n",
    "        human_thr = thr[0]\n",
    "    \n",
    "    \"\"\"Plot the ABR curves\"\"\"\n",
    "    data_range = range(0, 1000)    \n",
    "        \n",
    "    for sound_level in df.loc[df['frequency'] == _freq, 'sound_level']:\n",
    "        _ax.plot(data_range, \n",
    "                 sound_level + 2.5 * df[(df['sound_level'] == sound_level) & (df['frequency'] == _freq)][data_cols].iloc[0],\n",
    "                 linewidth=1.5, color='black')\n",
    "\n",
    "    if human_thr and human_thr != 999:\n",
    "        _ax.hlines(y=human_thr, \n",
    "                   xmin=data_range[0], xmax=data_range[-1], \n",
    "                   linewidth=2.5, linestyles=_linestyles[thr_manual], #+'_'+_cohort_type], \n",
    "                   color=_colors[thr_manual], zorder=100)\n",
    "        _ax.scatter(0, human_thr, marker=_markers[thr_manual], s=200, c=_colors[thr_manual])\n",
    "        line = Line2D([0], [0], color=_colors[thr_manual], marker=_markers[thr_manual], \n",
    "                      linestyle=_linestyles[thr_manual], ms=15, label=thr_manual)\n",
    "        if _legend_elements[thr_manual] is None:\n",
    "            _legend_elements[thr_manual] = line\n",
    "    if nn_thr and nn_thr != 999:\n",
    "        _ax.hlines(y=nn_thr,\n",
    "                   xmin=data_range[0], xmax=data_range[-1],\n",
    "                   linewidth=2.5, linestyles=_linestyles[thr_NN], #+'_'+_cohort_type], \n",
    "                   color=_colors[thr_NN], zorder=100)\n",
    "        _ax.scatter(0, nn_thr, marker=_markers[thr_NN], s=200, c=_colors[thr_NN])\n",
    "        line = Line2D([0], [0], color=_colors[thr_NN], marker=_markers[thr_NN], \n",
    "                      linestyle=_linestyles[thr_NN], ms=15, label=thr_NN)\n",
    "        if _legend_elements[thr_NN] is None:\n",
    "            _legend_elements[thr_NN] = line                       \n",
    "    if slr_thr and slr_thr != 999:\n",
    "        _ax.hlines(y=slr_thr,\n",
    "                   xmin=data_range[0], xmax=data_range[-1],\n",
    "                   linewidth=2.5, linestyles=_linestyles[thr_SLR], #+'_'+_cohort_type], \n",
    "                   color=_colors[thr_SLR], zorder=100)\n",
    "        _ax.scatter(0, slr_thr, marker=_markers[thr_SLR], s=200, c=_colors[thr_SLR])\n",
    "        line = Line2D([0], [0], color=_colors[thr_SLR], marker=_markers[thr_SLR], \n",
    "                      linestyle=_linestyles[thr_SLR], ms=15, label=thr_SLR)\n",
    "        if _legend_elements[thr_SLR] is None:\n",
    "            _legend_elements[thr_SLR] = line\n",
    "\n",
    "    return _legend_elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_mouse_thresholds(_mouse_id, _gene, _thr_data, _curves, _file_names, \n",
    "                          _colors, _linestyles, _markers, \n",
    "                          _figsize=(15,12), _fontsize=40, \n",
    "                          _xlabel='stimulation', _ylabel='threshold [dB]', _file_output_only=False): \n",
    "    \"\"\"\n",
    "    Plots the ABR curves at different sound levels for a given mouse identifier and stimulus frequency.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        _mouse_id: int (GMC) or string (ING)\n",
    "            A given mouse identifier contained in _thr_data and _curves.\n",
    "        \n",
    "        _gene: string\n",
    "            A given gene name contained in _thr_data.\n",
    "            \n",
    "        _thr_data: pandas-data-frame\n",
    "            It contains mouse phenotyping and thresholding data.\n",
    "        \n",
    "        _curves: pandas-data-frame\n",
    "            It contains time series for ABR curves. \n",
    "            It must contain columns for frequency ('frequency') and sound level ('sound_level'). \n",
    "            \n",
    "        _file_names: list\n",
    "            The file names under which the resulting plots are to be saved (both in pdf and jpg format).\n",
    "    \"\"\"\n",
    "    \n",
    "    data_source = _thr_data.source.unique().squeeze()\n",
    "    cols = ['th_manual', 'th_NN_'+data_source+'trained', 'th_SLR_'+data_source+'calibrated']\n",
    "    \n",
    "    mouse_id = _mouse_id\n",
    "    if data_source == 'GMC':\n",
    "        mouse_id = int(_mouse_id)\n",
    "    \n",
    "    markersize = 10\n",
    "    markerscale = 2\n",
    "    \n",
    "    with PdfPages(_file_names['pdf']+'.pdf') as pdf:\n",
    "        \n",
    "        fontsize = 40\n",
    "        \n",
    "        fig1, ax1 = plt.subplots(figsize=_figsize) #(30,24)\n",
    "        \n",
    "        xlabel = _xlabel\n",
    "        ylabel = _ylabel\n",
    "        \n",
    "        legend_elements = plot_thresholds4gene(_gene, cols, _thr_data, colors, markers, linestyles, labels, \n",
    "                                               _cohort_type=False, _estimator=np.median, _ci=None, _dodge=0.1, _mouse_id=_mouse_id,\n",
    "                                               _markersize=markersize, _markerscale=markerscale, \n",
    "                                               _fontsize=fontsize, _figlegend=True, _legend_outside=True, \n",
    "                                               _xlabel=xlabel, _ylabel=ylabel, _fig=fig1, _ax=ax1)  \n",
    "        ax1.set_title(\n",
    "            'mouse_id = %s' % mouse_id, fontsize=_fontsize+5, y=1.01)\n",
    "#         ax1.text(.01, 110, 'mouse_id = %s' % _mouse_id, fontsize=fontsize)\n",
    "        ax1.grid(zorder=0, color='lightgray')\n",
    "        ax1.tick_params(axis='both', which='major', labelsize=_fontsize-5)\n",
    "        ax1.legend(handles=legend_elements, loc='upper left', frameon=False, fontsize=_fontsize-5, ncol=1)\n",
    "         \n",
    "#         fig1.legend(handles=legend_elements, loc='lower left', bbox_to_anchor=(.035, 1.01), ncol=2,\n",
    "#                     borderaxespad=0, fancybox=True, fontsize=_fontsize-5)\n",
    "#         fig1.subplots_adjust(top=0.95)\n",
    "\n",
    "        pdf.savefig(fig1, bbox_inches = 'tight', papertype = 'letter')\n",
    "        fig1.savefig(_file_names['jpg']+'_thr_median.jpg', bbox_inches = 'tight', papertype = 'letter')\n",
    "        if _file_output_only:\n",
    "            plt.close()\n",
    "        \n",
    "        ##############################################################################################\n",
    "        \n",
    "        nrows = 3\n",
    "        ncols = 2\n",
    "\n",
    "        fig2, axs2 = plt.subplots(nrows, ncols, figsize=(ncols*15,nrows*12), sharey=True, sharex=True)\n",
    "        \n",
    "        axes = []\n",
    "        for ax1 in axs2: \n",
    "            for ax2 in ax1:\n",
    "                axes.append(ax2)\n",
    "           \n",
    "        legend_elements = {}\n",
    "        for col in cols:\n",
    "            legend_elements[col] = None\n",
    "        for idx,ax in enumerate(axes):\n",
    "            \n",
    "            xlabel = 'timesteps [overall 10ms]'\n",
    "            ylabel = _ylabel\n",
    "            \n",
    "            if idx%ncols > 0:\n",
    "                ylabel = None\n",
    "                    \n",
    "            if idx < nrows*ncols - ncols:\n",
    "                xlabel = None \n",
    "            \n",
    "            freq = _curves.frequency.unique()[idx]\n",
    "            legend_elements = plot_curves_per_mouse(mouse_id, _curves, freq, \n",
    "                                                    cols, fontsize, fig2, ax, _colors, _linestyles, _markers, \n",
    "                                                    legend_elements)\n",
    "            \n",
    "            ax.set_title('click' if freq == 100 else '%dkHz' % (freq/1000), fontsize=_fontsize+5, pad=15)\n",
    "            ax.grid(zorder=0, color='lightgray')    \n",
    "            ax.set_ylim(-10, 110) \n",
    "            ax.set_ylabel(ylabel, fontsize=_fontsize)\n",
    "            ax.set_xlabel(xlabel, fontsize=_fontsize, labelpad=20)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=_fontsize-5)\n",
    "        \n",
    "        for key,val  in list(legend_elements.items()):\n",
    "            if val is None:\n",
    "                del legend_elements[key]\n",
    "\n",
    "        fig2.legend(handles=[legend_elements[key] for key in legend_elements], loc='lower left', \n",
    "                    bbox_to_anchor=(.045, 1.0), ncol=3,\n",
    "                    borderaxespad=0, fancybox=True, fontsize=_fontsize)\n",
    "        fig2.subplots_adjust(top=0.9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        pdf.savefig(fig2, bbox_inches = 'tight', papertype = 'letter')\n",
    "        fig2.savefig(_file_names['jpg']+'_curves.jpg', bbox_inches = 'tight', papertype = 'letter')\n",
    "        if _file_output_only:\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMC data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'GMC'\n",
    "dataGMC = data[data.source == source]\n",
    "dataGMC = dataGMC.astype({\"stimulation\": str})\n",
    "display(dataGMC.head(2))\n",
    "\n",
    "curvesGMC = pd.read_csv(os.path.join(path2data, 'GMC', 'GMC_abr_curves.csv'))\n",
    "display(curvesGMC.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMC data - visualisation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genesGMC = dataGMC[dataGMC.cohort_type == 'mut'].gene.unique()\n",
    "\n",
    "print('Number of genes:\\t %d' % len(genesGMC))\n",
    "print('Number of mutants:\\t %d' % dataGMC[dataGMC.cohort_type == 'mut'].mouse_id.nunique())\n",
    "print('Number of controls:\\t %d' % dataGMC[dataGMC.cohort_type == 'con'].mouse_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_gene_thresholds2file('Nacc1', dataGMC, _labels=labels, _fontsize=30, _file_output_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "'''Plot hearing curves for all GMC genes and save plots to pdf/jpg files'''\n",
    "start_time = time.time()\n",
    "print('\\nStart time: ', time.strftime(\"%H:%M:%S\", time.gmtime(start_time)))\n",
    "\n",
    "for idx,gene in enumerate(genesGMC):\n",
    "    print('%d. %s' % (idx, gene))\n",
    "    plot_gene_thresholds2file(gene, dataGMC, _labels=labels, _fontsize=30, _file_output_only=True)\n",
    "    \n",
    "elapsed_time = time.time() - start_time            \n",
    "print('\\nElapsed time: %s' % time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gene = 'Nacc1'\n",
    "_gene_data = dataGMC[dataGMC.gene == gene].reset_index(drop=True)[['mouse_id', 'th_manual', 'th_NN_GMCtrained', 'th_SLR_GMCcalibrated', 'frequency']]\n",
    "_gene_data = _gene_data.astype({'mouse_id': 'int64'})\n",
    "_mice = _gene_data.mouse_id.unique()\n",
    "_df = pd.merge(left=curvesGMC[curvesGMC.mouse_id.isin(_mice)].reset_index(drop=True), \n",
    "               right=_gene_data, how='left', on=['mouse_id', 'frequency'])\n",
    "    \n",
    "dir_names,file_names = get_result_file_names(gene, ['pdf', 'jpg'], 'GMC')\n",
    "    \n",
    "print('%d. %s (n=%d)' % (1,gene,_gene_data.mouse_id.nunique()))\n",
    "\n",
    "mouseid = '30414506'\n",
    "for dn in dir_names:\n",
    "    file_names[dn] = os.path.join(dir_names[dn], mouseid)\n",
    "    plot_mouse_thresholds(mouseid, gene, dataGMC, _df, file_names, colors, linestyles, markers, \n",
    "                          _file_output_only=False, _figsize=(25,18), _fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "'''Plot hearing curves for all GMC mutant mice and save plots to pdf/jpg files'''\n",
    "start_time = time.time()\n",
    "print('\\nStart time: ', time.strftime(\"%H:%M:%S\", time.gmtime(start_time)))\n",
    "\n",
    "for idx,gene in enumerate(genesGMC):\n",
    "    \n",
    "    _gene_data = dataGMC[dataGMC.gene == gene].reset_index(drop=True)[['mouse_id', 'th_manual', 'th_NN_GMCtrained', 'th_SLR_GMCcalibrated', 'frequency']]\n",
    "    _gene_data = _gene_data.astype({'mouse_id': 'int64'})\n",
    "    _mice = _gene_data.mouse_id.unique()\n",
    "    _df = pd.merge(left=curvesGMC[curvesGMC.mouse_id.isin(_mice)].reset_index(drop=True), \n",
    "                   right=_gene_data, how='left', on=['mouse_id', 'frequency'])\n",
    "    \n",
    "    dir_names,file_names = get_result_file_names(gene, ['pdf', 'jpg'], 'GMC')\n",
    "    \n",
    "    print('%d. %s (n=%d)' % (idx,gene,_gene_data.mouse_id.nunique()))\n",
    "    \n",
    "    for mouseid in _mice:\n",
    "        mouseid = str(mouseid)\n",
    "        for dn in dir_names:\n",
    "            file_names[dn] = os.path.join(dir_names[dn], mouseid)\n",
    "        plot_mouse_thresholds(mouseid, gene, dataGMC, _df, file_names, colors, linestyles, markers, \n",
    "                              _file_output_only=True, _figsize=(25,18), _fontsize=30)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print('\\nElapsed time: %s' % time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ING data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'ING'\n",
    "dataING = data[data.source == source]\n",
    "dataING = dataING.astype({\"stimulation\": str})\n",
    "dataING = dataING.reset_index(drop=True)\n",
    "display(dataING.head(2))\n",
    "\n",
    "curvesING = pd.read_csv(os.path.join(path2data, 'ING', 'ING_abr_curves.csv'))\n",
    "display(curvesING.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ING data - visualisation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genesING = dataING[dataING.cohort_type == 'mut'].gene.unique()\n",
    "\n",
    "print('Number of genes:\\t %d' % len(genesING))\n",
    "print('Number of mutants:\\t %d' % dataING[dataING.cohort_type == 'mut'].mouse_id.nunique())\n",
    "print('Number of controls:\\t %d' % dataING[dataING.cohort_type == 'con'].mouse_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataING1 = pd.merge(left=dataING, right=ING_mouse_data[['mouse_id', 'cohort_type', 'Pipeline']].rename(columns={'Pipeline': 'pipeline'}), \n",
    "                    how='left', on=['mouse_id', 'cohort_type'])\n",
    "display(dataING1.head(2))\n",
    "print('Number of genes:\\t %d' % len(genesING))\n",
    "print('Number of mutants:\\t %d' % dataING1[dataING1.cohort_type == 'mut'].mouse_id.nunique())\n",
    "print('Number of controls:\\t %d' % dataING1[dataING1.cohort_type == 'con'].mouse_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "valid_genes = []\n",
    "for idx,gene in enumerate(genesING):\n",
    "    if gene == gene and ' ' not in gene:\n",
    "#         print('%d. %s' % (idx, gene))\n",
    "        valid_genes.append(gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataING1[(dataING1.cohort_type == 'mut')&(dataING1.gene.isin(valid_genes))].mouse_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gene = 'Gm12253'\n",
    "plot_gene_thresholds2file(gene, dataING1, _labels=labels, _fontsize=30, _file_output_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Plot hearing curves for all ING genes and save plots to pdf/jpg files'''\n",
    "for idx,gene in enumerate(genesING):\n",
    "    if idx >= 500:\n",
    "        if gene == gene and (' ' not in gene) and (dataING[dataING.gene == gene].stimulation.nunique() == 6):\n",
    "            print('%d. %s\\t(stimulations: %s)' % (idx, gene, dataING[dataING.gene == gene].stimulation.unique()))\n",
    "            plot_gene_thresholds2file(gene, dataING1, _labels=labels, _fontsize=30, _file_output_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gene = 'Gm12253'\n",
    "_gene_data = dataING1[dataING1.gene == gene].reset_index(drop=True)[['mouse_id', 'th_manual', 'th_NN_INGtrained', 'th_SLR_INGcalibrated', 'frequency']]\n",
    "_mice = _gene_data.mouse_id.unique()\n",
    "_df = pd.merge(left=curvesING[curvesING.mouse_id.isin(_mice)].reset_index(drop=True), \n",
    "               right=_gene_data, how='left', on=['mouse_id', 'frequency'])\n",
    "    \n",
    "dir_names,file_names = get_result_file_names(gene, ['pdf', 'jpg'], 'ING')\n",
    "    \n",
    "print('%d. %s (n=%d)' % (1,gene,_gene_data.mouse_id.nunique()))\n",
    "\n",
    "mouseid = 'M02271106 ABR'\n",
    "for dn in dir_names:\n",
    "    file_names[dn] = os.path.join(dir_names[dn], mouseid)\n",
    "    plot_mouse_thresholds(mouseid, gene, dataING1, _df, file_names, colors, linestyles, markers, \n",
    "                          _file_output_only=False, _figsize=(25,18), _fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Plot hearing curves for all ING mutant mice and save plots to pdf/jpg files'''\n",
    "start_time = time.time()\n",
    "print('\\nStart time: ', time.strftime(\"%H:%M:%S\", time.gmtime(start_time)))\n",
    "\n",
    "for idx,gene in enumerate(genesING):\n",
    "    if idx < 500:\n",
    "        if gene == gene and (' ' not in gene) and (dataING1[dataING1.gene == gene].stimulation.nunique() == 6):\n",
    "            _gene_data = dataING1[dataING1.gene == gene].reset_index(drop=True)[['mouse_id', 'th_manual', 'th_NN_INGtrained', 'th_SLR_INGcalibrated', 'frequency']]\n",
    "            _mice = _gene_data.mouse_id.unique()\n",
    "            _df = pd.merge(left=curvesING[curvesING.mouse_id.isin(_mice)].reset_index(drop=True), \n",
    "                           right=_gene_data, how='left', on=['mouse_id', 'frequency'])\n",
    "    \n",
    "            dir_names,file_names = get_result_file_names(gene, ['pdf', 'jpg'], 'ING')\n",
    "    \n",
    "            print('%d. %s (n=%d)' % (idx,gene,_gene_data.mouse_id.nunique()))\n",
    "    \n",
    "            for mouseid in _mice:\n",
    "                for dn in dir_names:\n",
    "                    file_names[dn] = os.path.join(dir_names[dn], mouseid.replace(' ', '_'))\n",
    "                plot_mouse_thresholds(mouseid, gene, dataING1, _df, file_names, colors, linestyles, markers, \n",
    "                                      _file_output_only=True, _figsize=(25,18), _fontsize=30)\n",
    "                \n",
    "elapsed_time = time.time() - start_time \n",
    "print('\\nElapsed time: %s' % time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mann-Whitney-U-Test\n",
    "\n",
    " Detect  mutant mouse lines that exhibit potential biologically meaningful changes in hearing using **Cliff's Delta** and</br>\n",
    " the p-values resulting from a **Wilcoxon rank sum test**, defined as the probability of getting a test statistics as large or larger</br>\n",
    " assuming mutant and control distributions are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "\n",
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def mannwhitneyu_test(_data, _data_source, _mouse_sex=None, _gene=None, _output=False, _min_mice=3):\n",
    "    \n",
    "    \"\"\"\n",
    "    Performs the Mann-Whitney-U-Test either for gene-related data (with at least 3 mutants) or for all animals in the data set.\n",
    "    All thresholding types are considered (manually assessed, NN predicted and SLR estimated).\n",
    "    \n",
    "    The effect size is also calculated by Cliff's delta.\n",
    "    \"\"\"\n",
    "    \n",
    "    th_columns=['th_manual', 'th_NN_'+_data_source+'trained', 'th_SLR_'+_data_source+'calibrated']\n",
    "    print(th_columns)\n",
    "    \n",
    "    if _data_source == 'GMC':\n",
    "        _data = _data.astype({'mouse_id': 'int64'})  \n",
    "    \n",
    "    for col in th_columns:\n",
    "        _data[col] = [100 if _data.at[idx, col] == 999 else _data.at[idx, col] for idx in _data.index]      \n",
    "    \n",
    "    if _data_source == 'GMC' and _mouse_sex is not None: \n",
    "        _data = _data[_data.sex == _mouse_sex].reset_index(drop=True)\n",
    "\n",
    "    if _gene is None:\n",
    "        genes = _data[(_data.cohort_type == 'mut') & (_data.gene != 'wildtype')].gene.unique()\n",
    "    else:\n",
    "        genes = [_gene]\n",
    "     \n",
    "    stimul_df = {}\n",
    "    for stimul in _data.stimulation.unique():\n",
    "        \n",
    "        key = str(int(float(stimul)))+'kHz' if stimul != 'click' else stimul\n",
    "        \n",
    "        stimul_df[key] = pd.DataFrame()\n",
    "        \n",
    "        stimul_data = _data[_data.stimulation == stimul].reset_index(drop=True)\n",
    "        \n",
    "        for idx,gene in enumerate(genes):\n",
    "            \n",
    "            stimul_df[key].at[idx, 'gene'] = gene\n",
    "            \n",
    "            muts = stimul_data[(stimul_data.gene == gene) \n",
    "                               & (stimul_data.cohort_type == 'mut')].reset_index(drop=True)\n",
    "            if _data_source == 'GMC':\n",
    "                cons = stimul_data[(stimul_data.cohort_id.isin(muts.reference_cohort.unique())) \n",
    "                                   & (stimul_data.cohort_type == 'con')].reset_index(drop=True)\n",
    "            else: \n",
    "                cons = stimul_data[(stimul_data.pipeline.isin(muts.pipeline.unique())) \n",
    "                                   & (stimul_data.cohort_type == 'con')].reset_index(drop=True) \n",
    "            \n",
    "            stimul_df[key].at[idx, 'mut_mice'] = int(muts.mouse_id.nunique())\n",
    "            stimul_df[key].at[idx, 'con_mice'] = int(cons.mouse_id.nunique())\n",
    "            \n",
    "            if muts.mouse_id.nunique() >= _min_mice and cons.mouse_id.nunique() >= _min_mice:\n",
    "                for th_col in th_columns:\n",
    "                    \n",
    "                    \"\"\" === use the pingouin statistical package === \"\"\"\n",
    "                    \n",
    "#                    _res = pg.mwu(muts[th_col].values, cons[th_col].values)\n",
    "#                     print('\\n%s: %i. %s, %s\\n %s\\n%s\\n' % (key, idx, gene, th_col, \n",
    "#                                                            res, mannwhitneyu(muts[th_col].values, cons[th_col].values)))\n",
    "                    \n",
    "#                    stimul_df[key].at[idx, key+'_'+th_col+'_pval'] = res['p-val'][0]\n",
    "#                    stimul_df[key].at[idx, key+'_'+th_col+'_CLES'] = _res['CLES'][0]\n",
    "\n",
    "                    \"\"\" === use scipy.stats === \"\"\"   \n",
    "\n",
    "#                     print(muts[th_col].values, cons[th_col].values)\n",
    "                    res = mannwhitneyu(muts[th_col].values, cons[th_col].values)\n",
    "#                     print('\\n%s: %i. %s, %s\\n%s\\n%s\\n' % (key, idx, gene, th_col, \n",
    "#                                                            res, pg.mwu(muts[th_col].values, cons[th_col].values)))\n",
    "        \n",
    "                    \"\"\"\n",
    "                    effect size: Cliff's delta (d)\n",
    "                    interpretation: small, >= 0.11; medium, >= 0.28; large, >= 0.43\n",
    "                    \"\"\"\n",
    "                    Cliffs_d = 2*res.statistic/(muts.mouse_id.nunique()*cons.mouse_id.nunique()) - 1\n",
    "#                     print('Cliff\\'s delta effect size: %f' % Cliffs_d)\n",
    "        \n",
    "                    VDA = (Cliffs_d + 1)/2\n",
    "#                     print('Vargha-Delaney A: %f' % VDA)\n",
    "                    \n",
    "                    stimul_df[key].at[idx, key+'_'+th_col+'_pval'] = res.pvalue\n",
    "                    stimul_df[key].at[idx, key+'_'+th_col+'_d'] = Cliffs_d\n",
    "                    stimul_df[key].at[idx, key+'_'+th_col+'_VDA'] = VDA\n",
    "    \n",
    "    return stimul_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def volcano_plot(_data, _test_results, _log=False, _fontsize=30, _ylim=(-0.2, 5.2),\n",
    "                 _cols=['th_manual', 'th_NN_GMCtrained', 'th_SLR_GMCcalibrated'], \n",
    "                 _coltitles = ['Manual', 'NN GMC-GMC', 'SLR GMC-GMC'],\n",
    "                 _stimul=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates volcano plots based on the Mann-Whitney-U-Test results.\n",
    "    \"\"\"\n",
    "    \n",
    "    fontsize = _fontsize\n",
    "    \n",
    "    small = 0.147\n",
    "    medium = 0.33\n",
    "    large = 0.474\n",
    "    \n",
    "    colors = {'small down': '#92C5DE',\n",
    "              'small up': '#F4A582', \n",
    "              'negligible': '#BBBBBB',\n",
    "              'medium down': '#4393C3',\n",
    "              'medium up': '#D6604D', \n",
    "              'large down': '#2166AC',\n",
    "              'large up': '#B2182B'}\n",
    "    \n",
    "    x_ticks = [-1., -large, -medium, -small, small, medium, large, 1., 1.5]\n",
    "    y_ticks = range(6)\n",
    "\n",
    "    if _stimul is None:\n",
    "        stimul = [st if st == 'click' else str(int(float(st)))+'kHz' for st in _data.stimulation.unique()] \n",
    "        noofcols = 3\n",
    "        noofrows = 6\n",
    "    else: \n",
    "        stimul = _stimul\n",
    "        noofcols = 3\n",
    "        noofrows = len(_stimul)\n",
    "    \n",
    "    if noofrows == 1:\n",
    "        figsize = (15*noofcols, 14)\n",
    "    else:\n",
    "        figsize = (15*noofcols, 13*noofrows)\n",
    "        \n",
    "    cols = []\n",
    "    for st in stimul:\n",
    "        for col in _cols:\n",
    "            cols.append(st+'_'+col)\n",
    "    \n",
    "    fig, axs = plt.subplots(noofrows, noofcols, sharey=True, sharex=True, figsize=figsize)\n",
    "    \n",
    "    legend_elements = [] \n",
    "    for label in colors: #['small down', 'small up', 'negligible', 'medium down', 'medium up', 'large down', 'large up']:\n",
    "        legend_elements.append(Line2D([0], [0], marker='o', color='w', label=label, \n",
    "                                      markerfacecolor=colors[label], markersize=20))\n",
    "    \n",
    "    axs1 = []\n",
    "    if noofrows == 1:\n",
    "        for ax in axs:\n",
    "            axs1.append(ax)\n",
    "    else:\n",
    "        for ax1 in axs:\n",
    "            for ax in ax1:\n",
    "                axs1.append(ax) \n",
    "    \n",
    "    # index for iterating the axes\n",
    "    i = 0\n",
    "    # index for iterating the columns\n",
    "    j = 0\n",
    "    for ax in axs1:\n",
    "        \n",
    "        x = _test_results[cols[i]+'_d']\n",
    "        xlabel = 'Cliff\\'s delta'\n",
    "        c = [colors['large down'] if _x<=-large else \n",
    "             colors['medium down'] if _x<=-medium else\n",
    "             colors['small down'] if _x<=-small else \n",
    "             colors['large up'] if _x>=large else \n",
    "             colors['medium up'] if _x>=medium else \n",
    "             colors['small up'] if _x>=small else \n",
    "             colors['negligible'] for _x in x]\n",
    "        \n",
    "        ax.axvline(x=-large, ls='--', lw=2, color=colors['large down'])\n",
    "        ax.axvline(x=-medium, ls='--', lw=1.5, color=colors['medium down'])\n",
    "        ax.axvline(x=-small, ls='--', lw=1.5, color=colors['small down'])\n",
    "        ax.axvline(x=small, ls='--', lw=1.5, color=colors['small up'])\n",
    "        ax.axvline(x=medium, ls='--', lw=1.5, color=colors['medium up'])\n",
    "        ax.axvline(x=large, ls='--', lw=2, color=colors['large up'])\n",
    "            \n",
    "        y = [-np.log10(pval) for pval in _test_results[cols[i]+'_pval']]\n",
    "        \n",
    "        scatter = ax.scatter(x, y, s=240, c=c)\n",
    "        if i%noofcols == 0:\n",
    "            ax.set_ylabel('-log10(p-val)', fontsize=fontsize)\n",
    "        if i >= (noofrows-1)*noofcols:\n",
    "            ax.set_xlabel(xlabel, fontsize=fontsize)\n",
    "        \n",
    "        ax.set_xlim(-1.2, 1.7)\n",
    "        ax.set_ylim(_ylim)\n",
    "        \n",
    "        if i > 0 and i%noofcols == 0: \n",
    "            j+=1\n",
    "        \n",
    "        if i < noofcols: \n",
    "            ax.set_title('%s\\n%s' % (_coltitles[i], stimul[j]), fontsize=fontsize+5, fontweight='bold', pad=15)#y=1.01)\n",
    "        else: \n",
    "            ax.set_title(stimul[j], fontsize=fontsize+5, fontweight='bold', pad=15)#y=1.01)\n",
    "        \n",
    "        ax.tick_params(axis='both', which='major', labelsize=fontsize-5)\n",
    "        ax.set_xticks(x_ticks)\n",
    "        ax.set_xticklabels(x_ticks, rotation=40)\n",
    "        \n",
    "        ax.axhline(y=-np.log10(0.05), ls='--', lw=2, color='#555555')\n",
    "        ax.text(x=1.10, y=-np.log10(0.05)+0.08, s='p-val=0.05', fontsize=fontsize-5)\n",
    "        ax.grid(zorder=0, color='lightgray') \n",
    "        \n",
    "        i+=1\n",
    "\n",
    "    leg = fig.legend(handles=legend_elements, loc='lower left', bbox_to_anchor= (0.02, 1.0), ncol=3, \n",
    "                     borderaxespad=0, frameon=True, fontsize=fontsize, title='Effect', title_fontsize=fontsize+10)\n",
    "    leg._legend_box.align = \"left\"\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mann-Withney-U-Test - GMC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Compute the test\"\"\"\n",
    "resultsGMC = mannwhitneyu_test(dataGMC, 'GMC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create a pandas-data-frame from the test results map\"\"\"\n",
    "for key in resultsGMC:\n",
    "    \n",
    "    if key == 'click':\n",
    "        dfGMC = resultsGMC[key]\n",
    "    else: \n",
    "        dfGMC = pd.merge(left=dfGMC, right=resultsGMC[key], how='left', on=['gene', 'mut_mice', 'con_mice'])\n",
    "\n",
    "dfGMC = dfGMC.astype({'mut_mice': 'int64', 'con_mice': 'int64'})\n",
    "display(dfGMC.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGMC.to_csv(os.path.join(path2results, 'volcano_plots', 'GMC_mannwhitneyu_results.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Volcano plots\"\"\"\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "fig = volcano_plot(dataGMC, dfGMC)\n",
    "fig.savefig(os.path.join(path2results, 'volcano_plots', 'GMC_volcano_plot.png'), bbox_inches = 'tight', papertype = 'letter')\n",
    "\n",
    "fig_click = volcano_plot(dataGMC, dfGMC, _stimul=['click'])\n",
    "fig_click.savefig(os.path.join(path2results, 'volcano_plots', 'GMC_volcano_plot_click.png'), bbox_inches = 'tight', papertype = 'letter')\n",
    "\n",
    "fig_30 = volcano_plot(dataGMC, dfGMC, _stimul=['30kHz'])\n",
    "fig_30.savefig(os.path.join(path2results, 'volcano_plots', 'GMC_volcano_plot_30kHz.png'), bbox_inches = 'tight', papertype = 'letter')\n",
    "\n",
    "fig_click_30 = volcano_plot(dataGMC, dfGMC, _stimul=['click','30kHz'])\n",
    "fig_click_30.savefig(os.path.join(path2results, 'volcano_plots', 'GMC_volcano_plot_click_30kHz.png'), bbox_inches = 'tight', papertype = 'letter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Test computation for females\"\"\"\n",
    "results_f = mannwhitneyu_test(dataGMC, _data_source='GMC', _mouse_sex='f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create a pandas-data-frame from the test results map\"\"\"\n",
    "for key in results_f:\n",
    "    \n",
    "    if key == 'click':\n",
    "        df_f = results_f[key]\n",
    "    else: \n",
    "        df_f = pd.merge(left=df_f, right=results_f[key], how='left', on=['gene', 'mut_mice', 'con_mice'])\n",
    "\n",
    "df_f = df_f.astype({'mut_mice': 'int64', 'con_mice': 'int64'})\n",
    "display(df_f.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f.to_csv(os.path.join(path2results, 'volcano_plots', '_GMC_mannwhitneyu_results_f.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Volcano plots\"\"\"\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "fig_f = volcano_plot(dataGMC, df_f)\n",
    "fig_f.savefig(os.path.join(path2results, 'volcano_plots', 'GMC_volcano_plot_f.png'), bbox_inches = 'tight', papertype = 'letter')\n",
    "\n",
    "fig_f_click = volcano_plot(dataGMC, df_f, _stimul=['click'])\n",
    "fig_f_click.savefig(os.path.join(path2results, 'volcano_plots', 'GMC_volcano_plot_f_click.png'), bbox_inches = 'tight', papertype = 'letter')\n",
    "\n",
    "fig_f_30 = volcano_plot(dataGMC, df_f, _stimul=['30kHz'])\n",
    "fig_f_30.savefig(os.path.join(path2results, 'volcano_plots', 'GMC_volcano_plot_f_30kHz.png'), bbox_inches = 'tight', papertype = 'letter')\n",
    "\n",
    "fig_f_click_30 = volcano_plot(dataGMC, df_f, _stimul=['click','30kHz'])\n",
    "fig_f_click_30.savefig(os.path.join(path2results, 'volcano_plots', 'GMC_volcano_plot_f_click_30kHz.png'), bbox_inches = 'tight', papertype = 'letter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Test computation for males\"\"\"\n",
    "results_m = mannwhitneyu_test(dataGMC, _data_source='GMC', _mouse_sex='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create a pandas-data-frame from the test results map\"\"\"\n",
    "for key in results_m:\n",
    "    \n",
    "    if key == 'click':\n",
    "        df_m = results_m[key]\n",
    "    else: \n",
    "        df_m = pd.merge(left=df_m, right=results_m[key], how='left', on=['gene', 'mut_mice', 'con_mice'])\n",
    "\n",
    "df_m = df_m.astype({'mut_mice': 'int64', 'con_mice': 'int64'})\n",
    "display(df_m.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m.to_csv(os.path.join(path2results, 'volcano_plots', '_GMC_mannwhitneyu_results_m.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Volcano plots\"\"\"\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "fig_m = volcano_plot(dataGMC, df_m)\n",
    "fig_m.savefig(os.path.join(path2results, 'volcano_plots', 'GMC_volcano_plot_m.png'), bbox_inches = 'tight', papertype = 'letter')\n",
    "\n",
    "fig_m_click = volcano_plot(dataGMC, df_m, _stimul=['click'])\n",
    "fig_m_click.savefig(os.path.join(path2results, 'volcano_plots', 'GMC_volcano_plot_m_click.png'), bbox_inches = 'tight', papertype = 'letter')\n",
    "\n",
    "fig_m_30 = volcano_plot(dataGMC, df_m, _stimul=['30kHz'])\n",
    "fig_m_30.savefig(os.path.join(path2results, 'volcano_plots', 'GMC_volcano_plot_m_30kHz.png'), bbox_inches = 'tight', papertype = 'letter')\n",
    "\n",
    "fig_m_click_30 = volcano_plot(dataGMC, df_m, _stimul=['click','30kHz'])\n",
    "fig_m_click_30.savefig(os.path.join(path2results, 'volcano_plots', 'GMC_volcano_plot_m_click_30kHz.png'), bbox_inches = 'tight', papertype = 'letter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mann-Whitney-U-Test - ING data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_mice = []\n",
    "for mouse_id in dataING.mouse_id.unique():\n",
    "    \n",
    "    _df = dataING1.loc[dataING1.mouse_id == mouse_id]\n",
    "    \n",
    "    gene = _df.gene.unique().squeeze()\n",
    "    cohort_type = _df.cohort_type.unique().squeeze()\n",
    "    no_of_stimulations = _df.stimulation.nunique()\n",
    "    \n",
    "#     print(mouse_id, gene, cohort_type, no_of_stimulations)\n",
    "    \n",
    "    if no_of_stimulations == 6:\n",
    "        if cohort_type == 'con':\n",
    "            valid_mice.append(mouse_id)\n",
    "        elif cohort_type == 'mut':\n",
    "            if gene == gene and (' ' not in gene):\n",
    "                valid_mice.append(mouse_id)\n",
    "\n",
    "dataING2 = dataING1[dataING1.mouse_id.isin(valid_mice)].reset_index(drop=True)\n",
    "dataING2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of genes:\\t %d' % dataING2.gene.nunique())\n",
    "print('Number of mutants:\\t %d' % dataING2[dataING2.cohort_type == 'mut'].mouse_id.nunique())\n",
    "print('Number of controls:\\t %d' % dataING2[dataING2.cohort_type == 'con'].mouse_id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Test computation for ING data\"\"\"\n",
    "resultsING = mannwhitneyu_test(dataING2, 'ING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create a pandas-data-frame from the test results map\"\"\"\n",
    "for key in resultsING:\n",
    "    \n",
    "    if key == 'click':\n",
    "        dfING = resultsING[key]\n",
    "    else: \n",
    "        dfING = pd.merge(left=dfING, right=resultsING[key], how='left', on=['gene', 'mut_mice', 'con_mice'])\n",
    "\n",
    "dfING.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfING.to_csv(os.path.join(path2results, 'volcano_plots', 'ING_mannwhitneyu_results.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Volcano plots\"\"\"\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "ylim = (-0.2, 12.2)\n",
    "\n",
    "fig = volcano_plot(dataING, dfING, _ylim=ylim,\n",
    "                   _cols=['th_manual', 'th_NN_INGtrained', 'th_SLR_INGcalibrated'], \n",
    "                   _coltitles = ['Manual', 'NN ING-ING', 'SLR ING-ING'])\n",
    "# fig.savefig(os.path.join(path2results, 'volcano_plots', 'ING_volcano_plot.png'), bbox_inches = 'tight', papertype = 'letter')\n",
    "\n",
    "fig_click = volcano_plot(dataING, dfING, _ylim=ylim, \n",
    "                         _cols=['th_manual', 'th_NN_INGtrained', 'th_SLR_INGcalibrated'], \n",
    "                         _coltitles = ['Manual', 'NN ING-ING', 'SLR ING-ING'], \n",
    "                         _stimul=['click'])\n",
    "# fig_click.savefig(os.path.join(path2results, 'volcano_plots', 'ING_volcano_plot_click.png'), bbox_inches = 'tight', papertype = 'letter')\n",
    "\n",
    "fig_30 = volcano_plot(dataING, dfING, _ylim=ylim, \n",
    "                      _cols=['th_manual', 'th_NN_INGtrained', 'th_SLR_INGcalibrated'], \n",
    "                      _coltitles = ['Manual', 'NN ING-ING', 'SLR ING-ING'], \n",
    "                      _stimul=['30kHz'])\n",
    "# fig_30.savefig(os.path.join(path2results, 'volcano_plots', 'ING_volcano_plot_30kHz.png'), bbox_inches = 'tight', papertype = 'letter')\n",
    "\n",
    "fig_click_30 = volcano_plot(dataING, dfING, _ylim=ylim, \n",
    "                            _cols=['th_manual', 'th_NN_INGtrained', 'th_SLR_INGcalibrated'], \n",
    "                            _coltitles = ['Manual', 'NN ING-ING', 'SLR ING-ING'], \n",
    "                            _stimul=['click','30kHz'])\n",
    "# fig_click_30.savefig(os.path.join(path2results, 'volcano_plots', 'ING_volcano_plot_click_30kHz.png'), bbox_inches = 'tight', papertype = 'letter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
